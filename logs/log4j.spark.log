19/03/29 13:15:02 INFO SparkContext: Running Spark version 2.1.0
19/03/29 13:15:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/03/29 13:15:05 INFO SecurityManager: Changing view acls to: Gustavo
19/03/29 13:15:05 INFO SecurityManager: Changing modify acls to: Gustavo
19/03/29 13:15:05 INFO SecurityManager: Changing view acls groups to: 
19/03/29 13:15:05 INFO SecurityManager: Changing modify acls groups to: 
19/03/29 13:15:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gustavo); groups with view permissions: Set(); users  with modify permissions: Set(Gustavo); groups with modify permissions: Set()
19/03/29 13:15:06 INFO Utils: Successfully started service 'sparkDriver' on port 50726.
19/03/29 13:15:06 INFO SparkEnv: Registering MapOutputTracker
19/03/29 13:15:06 INFO SparkEnv: Registering BlockManagerMaster
19/03/29 13:15:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/03/29 13:15:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/03/29 13:15:06 INFO DiskBlockManager: Created local directory at C:\Users\Gustavo\AppData\Local\Temp\blockmgr-32846244-7ae0-4316-9821-e272a8112795
19/03/29 13:15:06 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/03/29 13:15:06 INFO SparkEnv: Registering OutputCommitCoordinator
19/03/29 13:15:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/03/29 13:15:07 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/03/29 13:15:07 INFO SparkContext: Added JAR file:/C:/Users/Gustavo/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:50726/jars/sparklyr-2.0-2.11.jar with timestamp 1553886907855
19/03/29 13:15:08 INFO Executor: Starting executor ID driver on host localhost
19/03/29 13:15:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50747.
19/03/29 13:15:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:50747
19/03/29 13:15:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/03/29 13:15:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50747, None)
19/03/29 13:15:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:50747 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 50747, None)
19/03/29 13:15:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50747, None)
19/03/29 13:15:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50747, None)
19/03/29 13:15:10 INFO SharedState: Warehouse path is 'C:/Users/Gustavo/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive'.
19/03/29 13:15:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/03/29 13:15:14 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/03/29 13:15:15 INFO ObjectStore: ObjectStore, initialize called
19/03/29 13:15:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/03/29 13:15:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/03/29 13:15:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/03/29 13:15:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/03/29 13:15:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/03/29 13:15:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/03/29 13:15:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/03/29 13:15:23 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/03/29 13:15:23 INFO ObjectStore: Initialized ObjectStore
19/03/29 13:15:23 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/03/29 13:15:23 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/03/29 13:15:24 INFO HiveMetaStore: Added admin role in metastore
19/03/29 13:15:24 INFO HiveMetaStore: Added public role in metastore
19/03/29 13:15:24 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/03/29 13:15:25 INFO HiveMetaStore: 0: get_all_databases
19/03/29 13:15:25 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_all_databases	
19/03/29 13:15:25 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/03/29 13:15:25 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/03/29 13:15:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/03/29 13:15:25 INFO SessionState: Created local directory: C:/Users/Gustavo/AppData/Local/Temp/5f8c62cd-66d4-4b87-8083-42196b3a9704_resources
19/03/29 13:15:25 INFO SessionState: Created HDFS directory: C:/Users/Gustavo/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/Gustavo/5f8c62cd-66d4-4b87-8083-42196b3a9704
19/03/29 13:15:25 INFO SessionState: Created local directory: C:/Users/Gustavo/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/5f8c62cd-66d4-4b87-8083-42196b3a9704
19/03/29 13:15:26 INFO SessionState: Created HDFS directory: C:/Users/Gustavo/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/Gustavo/5f8c62cd-66d4-4b87-8083-42196b3a9704/_tmp_space.db
19/03/29 13:15:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Gustavo/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive
19/03/29 13:15:26 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:15:26 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:15:26 INFO HiveMetaStore: 0: get_database: global_temp
19/03/29 13:15:26 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/03/29 13:15:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/03/29 13:18:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 13:18:33 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:18:33 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:18:33 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:18:33 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:18:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 13:18:33 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 13:18:37 INFO CodeGenerator: Code generated in 735.489334 ms
19/03/29 13:18:38 INFO SparkContext: Starting job: collect at utils.scala:44
19/03/29 13:18:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/03/29 13:18:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/03/29 13:18:38 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:18:38 INFO DAGScheduler: Missing parents: List()
19/03/29 13:18:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41), which has no missing parents
19/03/29 13:18:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 912.3 MB)
19/03/29 13:18:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 912.3 MB)
19/03/29 13:18:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:50747 (size: 4.6 KB, free: 912.3 MB)
19/03/29 13:18:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
19/03/29 13:18:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41)
19/03/29 13:18:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/03/29 13:18:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
19/03/29 13:18:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/03/29 13:18:40 INFO Executor: Fetching spark://127.0.0.1:50726/jars/sparklyr-2.0-2.11.jar with timestamp 1553886907855
19/03/29 13:18:40 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:50726 after 74 ms (0 ms spent in bootstraps)
19/03/29 13:18:40 INFO Utils: Fetching spark://127.0.0.1:50726/jars/sparklyr-2.0-2.11.jar to C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058\fetchFileTemp3822057657936354679.tmp
19/03/29 13:18:41 INFO Executor: Adding file:/C:/Users/Gustavo/AppData/Local/Temp/spark-25ccc23e-0924-43d6-96b3-c7034bef0eac/userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058/sparklyr-2.0-2.11.jar to class loader
19/03/29 13:18:42 INFO CodeGenerator: Code generated in 34.582628 ms
19/03/29 13:18:42 INFO CodeGenerator: Code generated in 17.358262 ms
19/03/29 13:18:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
19/03/29 13:18:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2299 ms on localhost (executor driver) (1/1)
19/03/29 13:18:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/03/29 13:18:42 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 2.460 s
19/03/29 13:18:42 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 3.936269 s
19/03/29 13:18:42 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:50747 in memory (size: 4.6 KB, free: 912.3 MB)
19/03/29 13:18:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 238.7 KB, free 912.1 MB)
19/03/29 13:18:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.3 KB, free 912.0 MB)
19/03/29 13:18:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.3 MB)
19/03/29 13:18:43 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/03/29 13:18:43 INFO FileInputFormat: Total input paths to process : 1
19/03/29 13:18:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:18:43 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 13:18:43 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:43 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:18:43 INFO DAGScheduler: Missing parents: List()
19/03/29 13:18:43 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:18:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.5 KB, free 912.0 MB)
19/03/29 13:18:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 912.0 MB)
19/03/29 13:18:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.3 MB)
19/03/29 13:18:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
19/03/29 13:18:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/03/29 13:18:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6065 bytes)
19/03/29 13:18:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:18:44 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/29 13:18:44 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/29 13:18:44 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/29 13:18:44 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/29 13:18:44 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/29 13:18:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1206 bytes result sent to driver
19/03/29 13:18:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 405 ms on localhost (executor driver) (1/1)
19/03/29 13:18:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/03/29 13:18:44 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.421 s
19/03/29 13:18:44 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.442655 s
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 238.7 KB, free 911.8 MB)
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.3 KB, free 911.8 MB)
19/03/29 13:18:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.3 MB)
19/03/29 13:18:44 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/03/29 13:18:44 INFO FileInputFormat: Total input paths to process : 1
19/03/29 13:18:44 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:18:44 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 13:18:44 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:44 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:18:44 INFO DAGScheduler: Missing parents: List()
19/03/29 13:18:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 911.8 MB)
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.8 MB)
19/03/29 13:18:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.3 MB)
19/03/29 13:18:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
19/03/29 13:18:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/03/29 13:18:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6065 bytes)
19/03/29 13:18:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:18:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1119 bytes result sent to driver
19/03/29 13:18:44 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.016 s
19/03/29 13:18:44 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034380 s
19/03/29 13:18:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 16 ms on localhost (executor driver) (1/1)
19/03/29 13:18:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/03/29 13:18:44 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:18:44 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 48 output partitions
19/03/29 13:18:44 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:44 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:18:44 INFO DAGScheduler: Missing parents: List()
19/03/29 13:18:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.5 KB, free 911.8 MB)
19/03/29 13:18:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.8 KB, free 911.8 MB)
19/03/29 13:18:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:50747 (size: 4.8 KB, free: 912.2 MB)
19/03/29 13:18:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
19/03/29 13:18:44 INFO DAGScheduler: Submitting 48 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:18:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 48 tasks
19/03/29 13:18:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:18:44 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:18:44 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:18:44 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:18:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/03/29 13:18:44 INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
19/03/29 13:18:44 INFO ContextCleaner: Cleaned accumulator 1
19/03/29 13:18:44 INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
19/03/29 13:18:44 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
19/03/29 13:18:44 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:18:44 INFO ContextCleaner: Cleaned accumulator 0
19/03/29 13:18:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:33554432+33554432
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:67108864+33554432
19/03/29 13:18:44 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:100663296+33554432
19/03/29 13:18:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1489 bytes result sent to driver
19/03/29 13:18:58 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:18:58 INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
19/03/29 13:18:58 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:134217728+33554432
19/03/29 13:18:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13661 ms on localhost (executor driver) (1/48)
19/03/29 13:19:00 INFO Executor: Finished task 2.0 in stage 3.0 (TID 5). 1492 bytes result sent to driver
19/03/29 13:19:00 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:00 INFO Executor: Running task 5.0 in stage 3.0 (TID 8)
19/03/29 13:19:00 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 16084 ms on localhost (executor driver) (2/48)
19/03/29 13:19:00 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:167772160+33554432
19/03/29 13:19:00 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 1402 bytes result sent to driver
19/03/29 13:19:00 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:00 INFO Executor: Running task 6.0 in stage 3.0 (TID 9)
19/03/29 13:19:00 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 16170 ms on localhost (executor driver) (3/48)
19/03/29 13:19:00 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:201326592+33554432
19/03/29 13:19:09 INFO Executor: Finished task 3.0 in stage 3.0 (TID 6). 1489 bytes result sent to driver
19/03/29 13:19:09 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:09 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 24922 ms on localhost (executor driver) (4/48)
19/03/29 13:19:09 INFO Executor: Running task 7.0 in stage 3.0 (TID 10)
19/03/29 13:19:09 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:234881024+33554432
19/03/29 13:19:10 INFO Executor: Finished task 4.0 in stage 3.0 (TID 7). 1492 bytes result sent to driver
19/03/29 13:19:10 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:10 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 7) in 11978 ms on localhost (executor driver) (5/48)
19/03/29 13:19:10 INFO Executor: Running task 8.0 in stage 3.0 (TID 11)
19/03/29 13:19:10 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:268435456+33554432
19/03/29 13:19:16 INFO Executor: Finished task 5.0 in stage 3.0 (TID 8). 1492 bytes result sent to driver
19/03/29 13:19:16 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:16 INFO Executor: Running task 9.0 in stage 3.0 (TID 12)
19/03/29 13:19:16 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 8) in 15939 ms on localhost (executor driver) (6/48)
19/03/29 13:19:16 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:301989888+33554432
19/03/29 13:19:21 INFO Executor: Finished task 6.0 in stage 3.0 (TID 9). 1315 bytes result sent to driver
19/03/29 13:19:21 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:21 INFO Executor: Running task 10.0 in stage 3.0 (TID 13)
19/03/29 13:19:21 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 9) in 20809 ms on localhost (executor driver) (7/48)
19/03/29 13:19:21 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:335544320+33554432
19/03/29 13:19:24 INFO Executor: Finished task 8.0 in stage 3.0 (TID 11). 1315 bytes result sent to driver
19/03/29 13:19:24 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:24 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 14432 ms on localhost (executor driver) (8/48)
19/03/29 13:19:24 INFO Executor: Running task 11.0 in stage 3.0 (TID 14)
19/03/29 13:19:24 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:369098752+33554432
19/03/29 13:19:24 INFO Executor: Finished task 7.0 in stage 3.0 (TID 10). 1402 bytes result sent to driver
19/03/29 13:19:24 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:24 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 10) in 15219 ms on localhost (executor driver) (9/48)
19/03/29 13:19:24 INFO Executor: Running task 12.0 in stage 3.0 (TID 15)
19/03/29 13:19:24 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:402653184+33554432
19/03/29 13:19:31 INFO Executor: Finished task 9.0 in stage 3.0 (TID 12). 1402 bytes result sent to driver
19/03/29 13:19:31 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:31 INFO Executor: Running task 13.0 in stage 3.0 (TID 16)
19/03/29 13:19:31 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 12) in 15167 ms on localhost (executor driver) (10/48)
19/03/29 13:19:31 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:436207616+33554432
19/03/29 13:19:38 INFO Executor: Finished task 11.0 in stage 3.0 (TID 14). 1402 bytes result sent to driver
19/03/29 13:19:38 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:38 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 14) in 14161 ms on localhost (executor driver) (11/48)
19/03/29 13:19:38 INFO Executor: Running task 14.0 in stage 3.0 (TID 17)
19/03/29 13:19:38 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:469762048+33554432
19/03/29 13:19:39 INFO Executor: Finished task 10.0 in stage 3.0 (TID 13). 1315 bytes result sent to driver
19/03/29 13:19:39 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:39 INFO Executor: Running task 15.0 in stage 3.0 (TID 18)
19/03/29 13:19:39 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 13) in 18220 ms on localhost (executor driver) (12/48)
19/03/29 13:19:39 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:503316480+33554432
19/03/29 13:19:42 INFO Executor: Finished task 12.0 in stage 3.0 (TID 15). 1402 bytes result sent to driver
19/03/29 13:19:42 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:42 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 15) in 18005 ms on localhost (executor driver) (13/48)
19/03/29 13:19:42 INFO Executor: Running task 16.0 in stage 3.0 (TID 19)
19/03/29 13:19:42 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:536870912+33554432
19/03/29 13:19:45 INFO Executor: Finished task 13.0 in stage 3.0 (TID 16). 1315 bytes result sent to driver
19/03/29 13:19:45 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:45 INFO Executor: Running task 17.0 in stage 3.0 (TID 20)
19/03/29 13:19:45 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 16) in 13560 ms on localhost (executor driver) (14/48)
19/03/29 13:19:45 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:570425344+33554432
19/03/29 13:19:51 INFO Executor: Finished task 14.0 in stage 3.0 (TID 17). 1315 bytes result sent to driver
19/03/29 13:19:51 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:51 INFO Executor: Running task 18.0 in stage 3.0 (TID 21)
19/03/29 13:19:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:603979776+33554432
19/03/29 13:19:51 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 17) in 12628 ms on localhost (executor driver) (15/48)
19/03/29 13:19:52 INFO Executor: Finished task 15.0 in stage 3.0 (TID 18). 1492 bytes result sent to driver
19/03/29 13:19:52 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:52 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 18) in 13130 ms on localhost (executor driver) (16/48)
19/03/29 13:19:52 INFO Executor: Running task 19.0 in stage 3.0 (TID 22)
19/03/29 13:19:53 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:637534208+33554432
19/03/29 13:19:57 INFO Executor: Finished task 16.0 in stage 3.0 (TID 19). 1492 bytes result sent to driver
19/03/29 13:19:57 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:19:57 INFO Executor: Running task 20.0 in stage 3.0 (TID 23)
19/03/29 13:19:57 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 19) in 14861 ms on localhost (executor driver) (17/48)
19/03/29 13:19:57 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:671088640+33554432
19/03/29 13:20:02 INFO Executor: Finished task 17.0 in stage 3.0 (TID 20). 1315 bytes result sent to driver
19/03/29 13:20:02 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:02 INFO Executor: Running task 21.0 in stage 3.0 (TID 24)
19/03/29 13:20:02 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 20) in 17527 ms on localhost (executor driver) (18/48)
19/03/29 13:20:02 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:704643072+33554432
19/03/29 13:20:06 INFO Executor: Finished task 19.0 in stage 3.0 (TID 22). 1402 bytes result sent to driver
19/03/29 13:20:06 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:06 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 22) in 13367 ms on localhost (executor driver) (19/48)
19/03/29 13:20:06 INFO Executor: Running task 22.0 in stage 3.0 (TID 25)
19/03/29 13:20:06 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:738197504+33554432
19/03/29 13:20:07 INFO Executor: Finished task 18.0 in stage 3.0 (TID 21). 1315 bytes result sent to driver
19/03/29 13:20:07 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 26, localhost, executor driver, partition 23, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:07 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 21) in 15930 ms on localhost (executor driver) (20/48)
19/03/29 13:20:07 INFO Executor: Running task 23.0 in stage 3.0 (TID 26)
19/03/29 13:20:07 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:771751936+33554432
19/03/29 13:20:19 INFO Executor: Finished task 20.0 in stage 3.0 (TID 23). 1315 bytes result sent to driver
19/03/29 13:20:19 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 27, localhost, executor driver, partition 24, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:19 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 23) in 22244 ms on localhost (executor driver) (21/48)
19/03/29 13:20:19 INFO Executor: Running task 24.0 in stage 3.0 (TID 27)
19/03/29 13:20:19 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:805306368+33554432
19/03/29 13:20:20 INFO Executor: Finished task 21.0 in stage 3.0 (TID 24). 1315 bytes result sent to driver
19/03/29 13:20:20 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 28, localhost, executor driver, partition 25, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:20 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 24) in 17476 ms on localhost (executor driver) (22/48)
19/03/29 13:20:20 INFO Executor: Running task 25.0 in stage 3.0 (TID 28)
19/03/29 13:20:20 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:838860800+33554432
19/03/29 13:20:20 INFO Executor: Finished task 22.0 in stage 3.0 (TID 25). 1492 bytes result sent to driver
19/03/29 13:20:20 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 29, localhost, executor driver, partition 26, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:20 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 25) in 14524 ms on localhost (executor driver) (23/48)
19/03/29 13:20:20 INFO Executor: Running task 26.0 in stage 3.0 (TID 29)
19/03/29 13:20:20 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:872415232+33554432
19/03/29 13:20:21 INFO Executor: Finished task 23.0 in stage 3.0 (TID 26). 1402 bytes result sent to driver
19/03/29 13:20:21 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 30, localhost, executor driver, partition 27, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:21 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 26) in 14145 ms on localhost (executor driver) (24/48)
19/03/29 13:20:21 INFO Executor: Running task 27.0 in stage 3.0 (TID 30)
19/03/29 13:20:21 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:905969664+33554432
19/03/29 13:20:34 INFO Executor: Finished task 26.0 in stage 3.0 (TID 29). 1492 bytes result sent to driver
19/03/29 13:20:34 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 31, localhost, executor driver, partition 28, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:34 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 29) in 13571 ms on localhost (executor driver) (25/48)
19/03/29 13:20:34 INFO Executor: Running task 28.0 in stage 3.0 (TID 31)
19/03/29 13:20:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:939524096+33554432
19/03/29 13:20:34 INFO Executor: Finished task 27.0 in stage 3.0 (TID 30). 1315 bytes result sent to driver
19/03/29 13:20:34 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 32, localhost, executor driver, partition 29, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:34 INFO Executor: Running task 29.0 in stage 3.0 (TID 32)
19/03/29 13:20:34 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 30) in 13101 ms on localhost (executor driver) (26/48)
19/03/29 13:20:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:973078528+33554432
19/03/29 13:20:36 INFO Executor: Finished task 25.0 in stage 3.0 (TID 28). 1315 bytes result sent to driver
19/03/29 13:20:36 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 33, localhost, executor driver, partition 30, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:36 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 28) in 16297 ms on localhost (executor driver) (27/48)
19/03/29 13:20:36 INFO Executor: Running task 30.0 in stage 3.0 (TID 33)
19/03/29 13:20:36 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1006632960+33554432
19/03/29 13:20:43 INFO Executor: Finished task 24.0 in stage 3.0 (TID 27). 1492 bytes result sent to driver
19/03/29 13:20:43 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 34, localhost, executor driver, partition 31, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:43 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 27) in 23343 ms on localhost (executor driver) (28/48)
19/03/29 13:20:43 INFO Executor: Running task 31.0 in stage 3.0 (TID 34)
19/03/29 13:20:43 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1040187392+33554432
19/03/29 13:20:49 INFO Executor: Finished task 29.0 in stage 3.0 (TID 32). 1402 bytes result sent to driver
19/03/29 13:20:49 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 35, localhost, executor driver, partition 32, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:49 INFO Executor: Running task 32.0 in stage 3.0 (TID 35)
19/03/29 13:20:49 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 32) in 14773 ms on localhost (executor driver) (29/48)
19/03/29 13:20:49 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1073741824+33554432
19/03/29 13:20:50 INFO Executor: Finished task 30.0 in stage 3.0 (TID 33). 1492 bytes result sent to driver
19/03/29 13:20:50 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 36, localhost, executor driver, partition 33, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:50 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 33) in 14130 ms on localhost (executor driver) (30/48)
19/03/29 13:20:50 INFO Executor: Running task 33.0 in stage 3.0 (TID 36)
19/03/29 13:20:50 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1107296256+33554432
19/03/29 13:20:52 INFO Executor: Finished task 28.0 in stage 3.0 (TID 31). 1315 bytes result sent to driver
19/03/29 13:20:52 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 37, localhost, executor driver, partition 34, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:52 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 31) in 17836 ms on localhost (executor driver) (31/48)
19/03/29 13:20:52 INFO Executor: Running task 34.0 in stage 3.0 (TID 37)
19/03/29 13:20:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1140850688+33554432
19/03/29 13:20:59 INFO Executor: Finished task 31.0 in stage 3.0 (TID 34). 1492 bytes result sent to driver
19/03/29 13:20:59 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 38, localhost, executor driver, partition 35, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:20:59 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 34) in 16594 ms on localhost (executor driver) (32/48)
19/03/29 13:20:59 INFO Executor: Running task 35.0 in stage 3.0 (TID 38)
19/03/29 13:20:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1174405120+33554432
19/03/29 13:21:04 INFO Executor: Finished task 34.0 in stage 3.0 (TID 37). 1492 bytes result sent to driver
19/03/29 13:21:04 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 39, localhost, executor driver, partition 36, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:04 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 37) in 12496 ms on localhost (executor driver) (33/48)
19/03/29 13:21:04 INFO Executor: Running task 36.0 in stage 3.0 (TID 39)
19/03/29 13:21:04 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1207959552+33554432
19/03/29 13:21:04 INFO Executor: Finished task 33.0 in stage 3.0 (TID 36). 1492 bytes result sent to driver
19/03/29 13:21:04 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 40, localhost, executor driver, partition 37, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:04 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 36) in 14075 ms on localhost (executor driver) (34/48)
19/03/29 13:21:04 INFO Executor: Running task 37.0 in stage 3.0 (TID 40)
19/03/29 13:21:04 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1241513984+33554432
19/03/29 13:21:05 INFO Executor: Finished task 32.0 in stage 3.0 (TID 35). 1315 bytes result sent to driver
19/03/29 13:21:05 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 41, localhost, executor driver, partition 38, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:05 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 35) in 15669 ms on localhost (executor driver) (35/48)
19/03/29 13:21:05 INFO Executor: Running task 38.0 in stage 3.0 (TID 41)
19/03/29 13:21:05 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1275068416+33554432
19/03/29 13:21:13 INFO Executor: Finished task 35.0 in stage 3.0 (TID 38). 1315 bytes result sent to driver
19/03/29 13:21:13 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 42, localhost, executor driver, partition 39, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:13 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 38) in 13445 ms on localhost (executor driver) (36/48)
19/03/29 13:21:13 INFO Executor: Running task 39.0 in stage 3.0 (TID 42)
19/03/29 13:21:13 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1308622848+33554432
19/03/29 13:21:17 INFO Executor: Finished task 37.0 in stage 3.0 (TID 40). 1315 bytes result sent to driver
19/03/29 13:21:17 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 43, localhost, executor driver, partition 40, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:17 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 40) in 12161 ms on localhost (executor driver) (37/48)
19/03/29 13:21:17 INFO Executor: Running task 40.0 in stage 3.0 (TID 43)
19/03/29 13:21:17 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1342177280+33554432
19/03/29 13:21:17 INFO Executor: Finished task 36.0 in stage 3.0 (TID 39). 1402 bytes result sent to driver
19/03/29 13:21:17 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 44, localhost, executor driver, partition 41, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:17 INFO Executor: Running task 41.0 in stage 3.0 (TID 44)
19/03/29 13:21:17 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 39) in 12789 ms on localhost (executor driver) (38/48)
19/03/29 13:21:17 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1375731712+33554432
19/03/29 13:21:17 INFO Executor: Finished task 38.0 in stage 3.0 (TID 41). 1315 bytes result sent to driver
19/03/29 13:21:17 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 45, localhost, executor driver, partition 42, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:17 INFO Executor: Running task 42.0 in stage 3.0 (TID 45)
19/03/29 13:21:17 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 41) in 12498 ms on localhost (executor driver) (39/48)
19/03/29 13:21:17 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1409286144+33554432
19/03/29 13:21:28 INFO Executor: Finished task 40.0 in stage 3.0 (TID 43). 1402 bytes result sent to driver
19/03/29 13:21:28 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 46, localhost, executor driver, partition 43, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:28 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 43) in 11515 ms on localhost (executor driver) (40/48)
19/03/29 13:21:28 INFO Executor: Running task 43.0 in stage 3.0 (TID 46)
19/03/29 13:21:28 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1442840576+33554432
19/03/29 13:21:30 INFO Executor: Finished task 39.0 in stage 3.0 (TID 42). 1402 bytes result sent to driver
19/03/29 13:21:30 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 47, localhost, executor driver, partition 44, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:30 INFO Executor: Running task 44.0 in stage 3.0 (TID 47)
19/03/29 13:21:30 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 42) in 17189 ms on localhost (executor driver) (41/48)
19/03/29 13:21:30 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1476395008+33554432
19/03/29 13:21:31 INFO Executor: Finished task 41.0 in stage 3.0 (TID 44). 1492 bytes result sent to driver
19/03/29 13:21:31 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 48, localhost, executor driver, partition 45, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:31 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 44) in 13916 ms on localhost (executor driver) (42/48)
19/03/29 13:21:31 INFO Executor: Running task 45.0 in stage 3.0 (TID 48)
19/03/29 13:21:31 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1509949440+33554432
19/03/29 13:21:31 INFO Executor: Finished task 42.0 in stage 3.0 (TID 45). 1315 bytes result sent to driver
19/03/29 13:21:31 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 49, localhost, executor driver, partition 46, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:31 INFO Executor: Running task 46.0 in stage 3.0 (TID 49)
19/03/29 13:21:31 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 45) in 14009 ms on localhost (executor driver) (43/48)
19/03/29 13:21:31 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1543503872+33554432
19/03/29 13:21:39 INFO Executor: Finished task 43.0 in stage 3.0 (TID 46). 1492 bytes result sent to driver
19/03/29 13:21:39 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 50, localhost, executor driver, partition 47, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:21:39 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 46) in 11263 ms on localhost (executor driver) (44/48)
19/03/29 13:21:39 INFO Executor: Running task 47.0 in stage 3.0 (TID 50)
19/03/29 13:21:39 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1577058304+33608904
19/03/29 13:21:43 INFO Executor: Finished task 46.0 in stage 3.0 (TID 49). 1492 bytes result sent to driver
19/03/29 13:21:43 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 49) in 11698 ms on localhost (executor driver) (45/48)
19/03/29 13:21:43 INFO Executor: Finished task 44.0 in stage 3.0 (TID 47). 1492 bytes result sent to driver
19/03/29 13:21:43 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 47) in 13092 ms on localhost (executor driver) (46/48)
19/03/29 13:21:48 INFO Executor: Finished task 45.0 in stage 3.0 (TID 48). 1402 bytes result sent to driver
19/03/29 13:21:48 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 48) in 16576 ms on localhost (executor driver) (47/48)
19/03/29 13:21:48 INFO Executor: Finished task 47.0 in stage 3.0 (TID 50). 1492 bytes result sent to driver
19/03/29 13:21:48 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 50) in 8676 ms on localhost (executor driver) (48/48)
19/03/29 13:21:48 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 183.771 s
19/03/29 13:21:48 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 183.806802 s
19/03/29 13:21:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/03/29 13:21:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 13:21:48 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:21:48 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:21:48 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:21:48 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:21:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 13:21:48 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 13:21:49 INFO SparkSqlParser: Parsing command: chicago_raw.csv
19/03/29 13:22:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 13:22:45 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:22:45 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:22:45 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:22:45 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:22:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 13:22:45 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 13:22:45 INFO SparkContext: Starting job: collect at utils.scala:44
19/03/29 13:22:45 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/03/29 13:22:45 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:44)
19/03/29 13:22:45 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:22:45 INFO DAGScheduler: Missing parents: List()
19/03/29 13:22:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at map at utils.scala:41), which has no missing parents
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 911.8 MB)
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 911.8 MB)
19/03/29 13:22:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:50747 (size: 4.6 KB, free: 912.2 MB)
19/03/29 13:22:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
19/03/29 13:22:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at map at utils.scala:41)
19/03/29 13:22:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/03/29 13:22:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
19/03/29 13:22:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 51)
19/03/29 13:22:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 51). 896 bytes result sent to driver
19/03/29 13:22:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 51) in 0 ms on localhost (executor driver) (1/1)
19/03/29 13:22:45 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:44) finished in 0.000 s
19/03/29 13:22:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/03/29 13:22:45 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0.012846 s
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 238.7 KB, free 911.5 MB)
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.3 KB, free 911.5 MB)
19/03/29 13:22:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.2 MB)
19/03/29 13:22:45 INFO SparkContext: Created broadcast 7 from csv at NativeMethodAccessorImpl.java:0
19/03/29 13:22:45 INFO FileInputFormat: Total input paths to process : 1
19/03/29 13:22:45 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:22:45 INFO DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 13:22:45 INFO DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:45 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:22:45 INFO DAGScheduler: Missing parents: List()
19/03/29 13:22:45 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.5 KB, free 911.5 MB)
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.5 MB)
19/03/29 13:22:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:22:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
19/03/29 13:22:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/03/29 13:22:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 6065 bytes)
19/03/29 13:22:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 52)
19/03/29 13:22:45 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:22:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 52). 961 bytes result sent to driver
19/03/29 13:22:45 INFO DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.000 s
19/03/29 13:22:45 INFO DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 0.014347 s
19/03/29 13:22:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 52) in 0 ms on localhost (executor driver) (1/1)
19/03/29 13:22:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/03/29 13:22:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.7 KB, free 911.3 MB)
19/03/29 13:22:46 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.3 KB, free 911.2 MB)
19/03/29 13:22:46 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.2 MB)
19/03/29 13:22:46 INFO SparkContext: Created broadcast 9 from csv at NativeMethodAccessorImpl.java:0
19/03/29 13:22:46 INFO FileInputFormat: Total input paths to process : 1
19/03/29 13:22:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:22:46 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 13:22:46 INFO DAGScheduler: Final stage: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:46 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:22:46 INFO DAGScheduler: Missing parents: List()
19/03/29 13:22:46 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:22:46 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.5 KB, free 911.2 MB)
19/03/29 13:22:46 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.2 MB)
19/03/29 13:22:46 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:22:46 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
19/03/29 13:22:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:46 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/03/29 13:22:46 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6065 bytes)
19/03/29 13:22:46 INFO Executor: Running task 0.0 in stage 6.0 (TID 53)
19/03/29 13:22:46 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:22:46 INFO Executor: Finished task 0.0 in stage 6.0 (TID 53). 961 bytes result sent to driver
19/03/29 13:22:46 INFO DAGScheduler: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0) finished in 0.000 s
19/03/29 13:22:46 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.016746 s
19/03/29 13:22:46 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 53) in 0 ms on localhost (executor driver) (1/1)
19/03/29 13:22:46 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/03/29 13:22:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 13:22:46 INFO DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 48 output partitions
19/03/29 13:22:46 INFO DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:46 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:22:46 INFO DAGScheduler: Missing parents: List()
19/03/29 13:22:46 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:22:46 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.5 KB, free 911.2 MB)
19/03/29 13:22:46 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.8 KB, free 911.2 MB)
19/03/29 13:22:46 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:50747 (size: 4.8 KB, free: 912.2 MB)
19/03/29 13:22:46 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
19/03/29 13:22:46 INFO DAGScheduler: Submitting 48 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 13:22:46 INFO TaskSchedulerImpl: Adding task set 7.0 with 48 tasks
19/03/29 13:22:46 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:46 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:46 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 56, localhost, executor driver, partition 2, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:46 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 57, localhost, executor driver, partition 3, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:46 INFO Executor: Running task 0.0 in stage 7.0 (TID 54)
19/03/29 13:22:46 INFO Executor: Running task 1.0 in stage 7.0 (TID 55)
19/03/29 13:22:46 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:33554432+33554432
19/03/29 13:22:46 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 13:22:46 INFO Executor: Running task 2.0 in stage 7.0 (TID 56)
19/03/29 13:22:46 INFO Executor: Running task 3.0 in stage 7.0 (TID 57)
19/03/29 13:22:46 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:100663296+33554432
19/03/29 13:22:46 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:67108864+33554432
19/03/29 13:22:46 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:22:46 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 13:22:46 INFO ContextCleaner: Cleaned accumulator 1322
19/03/29 13:22:46 INFO ContextCleaner: Cleaned accumulator 1323
19/03/29 13:22:46 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:50747 in memory (size: 4.6 KB, free: 912.2 MB)
19/03/29 13:22:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 54). 1315 bytes result sent to driver
19/03/29 13:22:47 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 58, localhost, executor driver, partition 4, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:47 INFO Executor: Running task 4.0 in stage 7.0 (TID 58)
19/03/29 13:22:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 54) in 1583 ms on localhost (executor driver) (1/48)
19/03/29 13:22:47 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:134217728+33554432
19/03/29 13:22:47 INFO Executor: Finished task 1.0 in stage 7.0 (TID 55). 1315 bytes result sent to driver
19/03/29 13:22:47 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 59, localhost, executor driver, partition 5, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:47 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 55) in 1595 ms on localhost (executor driver) (2/48)
19/03/29 13:22:47 INFO Executor: Finished task 2.0 in stage 7.0 (TID 56). 1315 bytes result sent to driver
19/03/29 13:22:47 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 60, localhost, executor driver, partition 6, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:47 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 56) in 1589 ms on localhost (executor driver) (3/48)
19/03/29 13:22:47 INFO Executor: Running task 6.0 in stage 7.0 (TID 60)
19/03/29 13:22:47 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:201326592+33554432
19/03/29 13:22:47 INFO Executor: Running task 5.0 in stage 7.0 (TID 59)
19/03/29 13:22:47 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:167772160+33554432
19/03/29 13:22:47 INFO Executor: Finished task 3.0 in stage 7.0 (TID 57). 1315 bytes result sent to driver
19/03/29 13:22:47 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 61, localhost, executor driver, partition 7, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:47 INFO Executor: Running task 7.0 in stage 7.0 (TID 61)
19/03/29 13:22:47 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 57) in 1678 ms on localhost (executor driver) (4/48)
19/03/29 13:22:47 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:234881024+33554432
19/03/29 13:22:48 INFO Executor: Finished task 6.0 in stage 7.0 (TID 60). 1315 bytes result sent to driver
19/03/29 13:22:48 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 62, localhost, executor driver, partition 8, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:48 INFO Executor: Running task 8.0 in stage 7.0 (TID 62)
19/03/29 13:22:48 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 60) in 1211 ms on localhost (executor driver) (5/48)
19/03/29 13:22:48 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:268435456+33554432
19/03/29 13:22:48 INFO Executor: Finished task 4.0 in stage 7.0 (TID 58). 1402 bytes result sent to driver
19/03/29 13:22:48 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 63, localhost, executor driver, partition 9, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:48 INFO Executor: Running task 9.0 in stage 7.0 (TID 63)
19/03/29 13:22:48 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 58) in 1243 ms on localhost (executor driver) (6/48)
19/03/29 13:22:48 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:301989888+33554432
19/03/29 13:22:48 INFO Executor: Finished task 5.0 in stage 7.0 (TID 59). 1315 bytes result sent to driver
19/03/29 13:22:48 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 64, localhost, executor driver, partition 10, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:48 INFO Executor: Running task 10.0 in stage 7.0 (TID 64)
19/03/29 13:22:48 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 59) in 1249 ms on localhost (executor driver) (7/48)
19/03/29 13:22:48 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:335544320+33554432
19/03/29 13:22:48 INFO Executor: Finished task 7.0 in stage 7.0 (TID 61). 1402 bytes result sent to driver
19/03/29 13:22:49 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 65, localhost, executor driver, partition 11, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:49 INFO Executor: Running task 11.0 in stage 7.0 (TID 65)
19/03/29 13:22:49 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 61) in 1236 ms on localhost (executor driver) (8/48)
19/03/29 13:22:49 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:369098752+33554432
19/03/29 13:22:50 INFO Executor: Finished task 8.0 in stage 7.0 (TID 62). 1402 bytes result sent to driver
19/03/29 13:22:50 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 66, localhost, executor driver, partition 12, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:50 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 62) in 1158 ms on localhost (executor driver) (9/48)
19/03/29 13:22:50 INFO Executor: Running task 12.0 in stage 7.0 (TID 66)
19/03/29 13:22:50 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:402653184+33554432
19/03/29 13:22:50 INFO Executor: Finished task 9.0 in stage 7.0 (TID 63). 1402 bytes result sent to driver
19/03/29 13:22:50 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 67, localhost, executor driver, partition 13, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:50 INFO Executor: Running task 13.0 in stage 7.0 (TID 67)
19/03/29 13:22:50 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 63) in 1189 ms on localhost (executor driver) (10/48)
19/03/29 13:22:50 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:436207616+33554432
19/03/29 13:22:50 INFO Executor: Finished task 10.0 in stage 7.0 (TID 64). 1492 bytes result sent to driver
19/03/29 13:22:50 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 68, localhost, executor driver, partition 14, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:50 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 64) in 1171 ms on localhost (executor driver) (11/48)
19/03/29 13:22:50 INFO Executor: Running task 14.0 in stage 7.0 (TID 68)
19/03/29 13:22:50 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:469762048+33554432
19/03/29 13:22:50 INFO Executor: Finished task 11.0 in stage 7.0 (TID 65). 1402 bytes result sent to driver
19/03/29 13:22:50 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 69, localhost, executor driver, partition 15, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:50 INFO Executor: Running task 15.0 in stage 7.0 (TID 69)
19/03/29 13:22:50 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 65) in 1214 ms on localhost (executor driver) (12/48)
19/03/29 13:22:50 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:503316480+33554432
19/03/29 13:22:51 INFO Executor: Finished task 12.0 in stage 7.0 (TID 66). 1315 bytes result sent to driver
19/03/29 13:22:51 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 70, localhost, executor driver, partition 16, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:51 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 66) in 1147 ms on localhost (executor driver) (13/48)
19/03/29 13:22:51 INFO Executor: Running task 16.0 in stage 7.0 (TID 70)
19/03/29 13:22:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:536870912+33554432
19/03/29 13:22:51 INFO Executor: Finished task 13.0 in stage 7.0 (TID 67). 1315 bytes result sent to driver
19/03/29 13:22:51 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 71, localhost, executor driver, partition 17, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:51 INFO Executor: Running task 17.0 in stage 7.0 (TID 71)
19/03/29 13:22:51 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 67) in 1145 ms on localhost (executor driver) (14/48)
19/03/29 13:22:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:570425344+33554432
19/03/29 13:22:51 INFO Executor: Finished task 14.0 in stage 7.0 (TID 68). 1492 bytes result sent to driver
19/03/29 13:22:51 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 72, localhost, executor driver, partition 18, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:51 INFO Executor: Running task 18.0 in stage 7.0 (TID 72)
19/03/29 13:22:51 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 68) in 1157 ms on localhost (executor driver) (15/48)
19/03/29 13:22:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:603979776+33554432
19/03/29 13:22:51 INFO Executor: Finished task 15.0 in stage 7.0 (TID 69). 1315 bytes result sent to driver
19/03/29 13:22:51 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 73, localhost, executor driver, partition 19, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:51 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 69) in 1127 ms on localhost (executor driver) (16/48)
19/03/29 13:22:51 INFO Executor: Running task 19.0 in stage 7.0 (TID 73)
19/03/29 13:22:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:637534208+33554432
19/03/29 13:22:52 INFO Executor: Finished task 16.0 in stage 7.0 (TID 70). 1402 bytes result sent to driver
19/03/29 13:22:52 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 74, localhost, executor driver, partition 20, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:52 INFO Executor: Running task 20.0 in stage 7.0 (TID 74)
19/03/29 13:22:52 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 70) in 1077 ms on localhost (executor driver) (17/48)
19/03/29 13:22:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:671088640+33554432
19/03/29 13:22:52 INFO Executor: Finished task 17.0 in stage 7.0 (TID 71). 1492 bytes result sent to driver
19/03/29 13:22:52 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 75, localhost, executor driver, partition 21, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:52 INFO Executor: Running task 21.0 in stage 7.0 (TID 75)
19/03/29 13:22:52 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 71) in 1076 ms on localhost (executor driver) (18/48)
19/03/29 13:22:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:704643072+33554432
19/03/29 13:22:52 INFO Executor: Finished task 18.0 in stage 7.0 (TID 72). 1492 bytes result sent to driver
19/03/29 13:22:52 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 76, localhost, executor driver, partition 22, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:52 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 72) in 1074 ms on localhost (executor driver) (19/48)
19/03/29 13:22:52 INFO Executor: Running task 22.0 in stage 7.0 (TID 76)
19/03/29 13:22:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:738197504+33554432
19/03/29 13:22:52 INFO Executor: Finished task 19.0 in stage 7.0 (TID 73). 1402 bytes result sent to driver
19/03/29 13:22:52 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 77, localhost, executor driver, partition 23, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:52 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 73) in 1084 ms on localhost (executor driver) (20/48)
19/03/29 13:22:52 INFO Executor: Running task 23.0 in stage 7.0 (TID 77)
19/03/29 13:22:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:771751936+33554432
19/03/29 13:22:53 INFO Executor: Finished task 20.0 in stage 7.0 (TID 74). 1315 bytes result sent to driver
19/03/29 13:22:53 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 78, localhost, executor driver, partition 24, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:53 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 74) in 1080 ms on localhost (executor driver) (21/48)
19/03/29 13:22:53 INFO Executor: Running task 24.0 in stage 7.0 (TID 78)
19/03/29 13:22:53 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:805306368+33554432
19/03/29 13:22:53 INFO Executor: Finished task 21.0 in stage 7.0 (TID 75). 1315 bytes result sent to driver
19/03/29 13:22:53 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 79, localhost, executor driver, partition 25, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:53 INFO Executor: Running task 25.0 in stage 7.0 (TID 79)
19/03/29 13:22:53 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 75) in 1078 ms on localhost (executor driver) (22/48)
19/03/29 13:22:53 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:838860800+33554432
19/03/29 13:22:53 INFO Executor: Finished task 22.0 in stage 7.0 (TID 76). 1315 bytes result sent to driver
19/03/29 13:22:53 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 80, localhost, executor driver, partition 26, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:53 INFO Executor: Running task 26.0 in stage 7.0 (TID 80)
19/03/29 13:22:53 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 76) in 1106 ms on localhost (executor driver) (23/48)
19/03/29 13:22:53 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:872415232+33554432
19/03/29 13:22:53 INFO Executor: Finished task 23.0 in stage 7.0 (TID 77). 1492 bytes result sent to driver
19/03/29 13:22:53 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 81, localhost, executor driver, partition 27, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:53 INFO Executor: Running task 27.0 in stage 7.0 (TID 81)
19/03/29 13:22:53 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 77) in 1136 ms on localhost (executor driver) (24/48)
19/03/29 13:22:53 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:905969664+33554432
19/03/29 13:22:54 INFO Executor: Finished task 24.0 in stage 7.0 (TID 78). 1492 bytes result sent to driver
19/03/29 13:22:54 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 82, localhost, executor driver, partition 28, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:54 INFO Executor: Running task 28.0 in stage 7.0 (TID 82)
19/03/29 13:22:54 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 78) in 1152 ms on localhost (executor driver) (25/48)
19/03/29 13:22:54 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:939524096+33554432
19/03/29 13:22:54 INFO Executor: Finished task 25.0 in stage 7.0 (TID 79). 1315 bytes result sent to driver
19/03/29 13:22:54 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 83, localhost, executor driver, partition 29, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:54 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 79) in 1132 ms on localhost (executor driver) (26/48)
19/03/29 13:22:54 INFO Executor: Running task 29.0 in stage 7.0 (TID 83)
19/03/29 13:22:54 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:973078528+33554432
19/03/29 13:22:54 INFO Executor: Finished task 26.0 in stage 7.0 (TID 80). 1315 bytes result sent to driver
19/03/29 13:22:54 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 84, localhost, executor driver, partition 30, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:54 INFO Executor: Running task 30.0 in stage 7.0 (TID 84)
19/03/29 13:22:54 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 80) in 1172 ms on localhost (executor driver) (27/48)
19/03/29 13:22:54 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1006632960+33554432
19/03/29 13:22:54 INFO Executor: Finished task 27.0 in stage 7.0 (TID 81). 1402 bytes result sent to driver
19/03/29 13:22:54 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 85, localhost, executor driver, partition 31, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:54 INFO Executor: Running task 31.0 in stage 7.0 (TID 85)
19/03/29 13:22:54 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 81) in 1084 ms on localhost (executor driver) (28/48)
19/03/29 13:22:54 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1040187392+33554432
19/03/29 13:22:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:50747 in memory (size: 4.8 KB, free: 912.2 MB)
19/03/29 13:22:55 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.2 MB)
19/03/29 13:22:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.2 MB)
19/03/29 13:22:55 INFO Executor: Finished task 28.0 in stage 7.0 (TID 82). 1492 bytes result sent to driver
19/03/29 13:22:55 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 86, localhost, executor driver, partition 32, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:55 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 82) in 1201 ms on localhost (executor driver) (29/48)
19/03/29 13:22:55 INFO Executor: Running task 32.0 in stage 7.0 (TID 86)
19/03/29 13:22:55 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1073741824+33554432
19/03/29 13:22:55 INFO Executor: Finished task 29.0 in stage 7.0 (TID 83). 1315 bytes result sent to driver
19/03/29 13:22:55 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 87, localhost, executor driver, partition 33, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:55 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 83) in 1262 ms on localhost (executor driver) (30/48)
19/03/29 13:22:55 INFO Executor: Running task 33.0 in stage 7.0 (TID 87)
19/03/29 13:22:55 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1107296256+33554432
19/03/29 13:22:55 INFO Executor: Finished task 30.0 in stage 7.0 (TID 84). 1402 bytes result sent to driver
19/03/29 13:22:55 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 88, localhost, executor driver, partition 34, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:55 INFO Executor: Running task 34.0 in stage 7.0 (TID 88)
19/03/29 13:22:55 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 84) in 1252 ms on localhost (executor driver) (31/48)
19/03/29 13:22:55 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1140850688+33554432
19/03/29 13:22:55 INFO Executor: Finished task 31.0 in stage 7.0 (TID 85). 1315 bytes result sent to driver
19/03/29 13:22:55 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 89, localhost, executor driver, partition 35, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:55 INFO Executor: Running task 35.0 in stage 7.0 (TID 89)
19/03/29 13:22:55 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 85) in 1252 ms on localhost (executor driver) (32/48)
19/03/29 13:22:55 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1174405120+33554432
19/03/29 13:22:56 INFO Executor: Finished task 32.0 in stage 7.0 (TID 86). 1315 bytes result sent to driver
19/03/29 13:22:56 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 90, localhost, executor driver, partition 36, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:56 INFO Executor: Running task 36.0 in stage 7.0 (TID 90)
19/03/29 13:22:56 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 86) in 1090 ms on localhost (executor driver) (33/48)
19/03/29 13:22:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1207959552+33554432
19/03/29 13:22:56 INFO Executor: Finished task 33.0 in stage 7.0 (TID 87). 1402 bytes result sent to driver
19/03/29 13:22:56 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 91, localhost, executor driver, partition 37, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:56 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 87) in 1097 ms on localhost (executor driver) (34/48)
19/03/29 13:22:56 INFO Executor: Running task 37.0 in stage 7.0 (TID 91)
19/03/29 13:22:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1241513984+33554432
19/03/29 13:22:56 INFO Executor: Finished task 34.0 in stage 7.0 (TID 88). 1402 bytes result sent to driver
19/03/29 13:22:56 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 92, localhost, executor driver, partition 38, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:56 INFO Executor: Running task 38.0 in stage 7.0 (TID 92)
19/03/29 13:22:56 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 88) in 1093 ms on localhost (executor driver) (35/48)
19/03/29 13:22:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1275068416+33554432
19/03/29 13:22:56 INFO Executor: Finished task 35.0 in stage 7.0 (TID 89). 1315 bytes result sent to driver
19/03/29 13:22:56 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 93, localhost, executor driver, partition 39, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:56 INFO Executor: Running task 39.0 in stage 7.0 (TID 93)
19/03/29 13:22:56 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 89) in 1094 ms on localhost (executor driver) (36/48)
19/03/29 13:22:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1308622848+33554432
19/03/29 13:22:57 INFO Executor: Finished task 36.0 in stage 7.0 (TID 90). 1402 bytes result sent to driver
19/03/29 13:22:57 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 94, localhost, executor driver, partition 40, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:57 INFO Executor: Running task 40.0 in stage 7.0 (TID 94)
19/03/29 13:22:57 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 90) in 1114 ms on localhost (executor driver) (37/48)
19/03/29 13:22:57 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1342177280+33554432
19/03/29 13:22:57 INFO Executor: Finished task 37.0 in stage 7.0 (TID 91). 1315 bytes result sent to driver
19/03/29 13:22:57 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 95, localhost, executor driver, partition 41, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:57 INFO Executor: Running task 41.0 in stage 7.0 (TID 95)
19/03/29 13:22:57 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 91) in 1096 ms on localhost (executor driver) (38/48)
19/03/29 13:22:57 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1375731712+33554432
19/03/29 13:22:58 INFO Executor: Finished task 38.0 in stage 7.0 (TID 92). 1402 bytes result sent to driver
19/03/29 13:22:58 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 96, localhost, executor driver, partition 42, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:58 INFO Executor: Running task 42.0 in stage 7.0 (TID 96)
19/03/29 13:22:58 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 92) in 1091 ms on localhost (executor driver) (39/48)
19/03/29 13:22:58 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1409286144+33554432
19/03/29 13:22:58 INFO Executor: Finished task 39.0 in stage 7.0 (TID 93). 1315 bytes result sent to driver
19/03/29 13:22:58 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 97, localhost, executor driver, partition 43, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:58 INFO Executor: Running task 43.0 in stage 7.0 (TID 97)
19/03/29 13:22:58 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 93) in 1089 ms on localhost (executor driver) (40/48)
19/03/29 13:22:58 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1442840576+33554432
19/03/29 13:22:59 INFO Executor: Finished task 40.0 in stage 7.0 (TID 94). 1492 bytes result sent to driver
19/03/29 13:22:59 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 98, localhost, executor driver, partition 44, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:59 INFO Executor: Running task 44.0 in stage 7.0 (TID 98)
19/03/29 13:22:59 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 94) in 1127 ms on localhost (executor driver) (41/48)
19/03/29 13:22:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1476395008+33554432
19/03/29 13:22:59 INFO Executor: Finished task 41.0 in stage 7.0 (TID 95). 1315 bytes result sent to driver
19/03/29 13:22:59 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 99, localhost, executor driver, partition 45, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:59 INFO Executor: Running task 45.0 in stage 7.0 (TID 99)
19/03/29 13:22:59 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 95) in 1131 ms on localhost (executor driver) (42/48)
19/03/29 13:22:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1509949440+33554432
19/03/29 13:22:59 INFO Executor: Finished task 42.0 in stage 7.0 (TID 96). 1402 bytes result sent to driver
19/03/29 13:22:59 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 100, localhost, executor driver, partition 46, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:59 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 96) in 1112 ms on localhost (executor driver) (43/48)
19/03/29 13:22:59 INFO Executor: Running task 46.0 in stage 7.0 (TID 100)
19/03/29 13:22:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1543503872+33554432
19/03/29 13:22:59 INFO Executor: Finished task 43.0 in stage 7.0 (TID 97). 1402 bytes result sent to driver
19/03/29 13:22:59 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 101, localhost, executor driver, partition 47, PROCESS_LOCAL, 6069 bytes)
19/03/29 13:22:59 INFO Executor: Running task 47.0 in stage 7.0 (TID 101)
19/03/29 13:22:59 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 97) in 1110 ms on localhost (executor driver) (44/48)
19/03/29 13:22:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1577058304+33608904
19/03/29 13:23:00 INFO Executor: Finished task 44.0 in stage 7.0 (TID 98). 1315 bytes result sent to driver
19/03/29 13:23:00 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 98) in 1108 ms on localhost (executor driver) (45/48)
19/03/29 13:23:00 INFO Executor: Finished task 45.0 in stage 7.0 (TID 99). 1402 bytes result sent to driver
19/03/29 13:23:00 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 99) in 1138 ms on localhost (executor driver) (46/48)
19/03/29 13:23:00 INFO Executor: Finished task 47.0 in stage 7.0 (TID 101). 1402 bytes result sent to driver
19/03/29 13:23:00 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 101) in 1115 ms on localhost (executor driver) (47/48)
19/03/29 13:23:00 INFO Executor: Finished task 46.0 in stage 7.0 (TID 100). 1402 bytes result sent to driver
19/03/29 13:23:00 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 100) in 1165 ms on localhost (executor driver) (48/48)
19/03/29 13:23:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/03/29 13:23:00 INFO DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0) finished in 14.236 s
19/03/29 13:23:00 INFO DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 14.235267 s
19/03/29 13:23:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 13:23:00 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:23:00 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:23:00 INFO HiveMetaStore: 0: get_database: default
19/03/29 13:23:00 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 13:23:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 13:23:00 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 13:23:00 INFO SparkSqlParser: Parsing command: chicago_raw
19/03/29 13:23:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `chicago_raw`
19/03/29 13:23:00 INFO SparkSqlParser: Parsing command: `chicago_raw`
19/03/29 13:23:00 INFO FileSourceStrategy: Pruning directories with: 
19/03/29 13:23:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/03/29 13:23:00 INFO FileSourceStrategy: Output Data Schema: struct<ID: int, Case Number: string, Date: string, Block: string, IUCR: string ... 20 more fields>
19/03/29 13:23:00 INFO FileSourceStrategy: Pushed Filters: 
19/03/29 13:23:00 INFO CodeGenerator: Code generated in 41.282963 ms
19/03/29 13:23:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 282.7 KB, free 911.5 MB)
19/03/29 13:23:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.5 MB)
19/03/29 13:23:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:50747 (size: 24.2 KB, free: 912.2 MB)
19/03/29 13:23:00 INFO SparkContext: Created broadcast 12 from sql at NativeMethodAccessorImpl.java:0
19/03/29 13:23:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
19/03/29 13:23:01 INFO CodeGenerator: Code generated in 40.775842 ms
19/03/29 13:23:01 INFO CodeGenerator: Code generated in 16.087428 ms
19/03/29 13:23:01 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/03/29 13:23:01 INFO DAGScheduler: Registering RDD 34 (sql at NativeMethodAccessorImpl.java:0)
19/03/29 13:23:01 INFO DAGScheduler: Got job 8 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 13:23:01 INFO DAGScheduler: Final stage: ResultStage 9 (sql at NativeMethodAccessorImpl.java:0)
19/03/29 13:23:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/03/29 13:23:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/03/29 13:23:01 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:23:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 36.3 KB, free 911.4 MB)
19/03/29 13:23:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 15.0 KB, free 911.4 MB)
19/03/29 13:23:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:50747 (size: 15.0 KB, free: 912.2 MB)
19/03/29 13:23:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
19/03/29 13:23:01 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at sql at NativeMethodAccessorImpl.java:0)
19/03/29 13:23:01 INFO TaskSchedulerImpl: Adding task set 8.0 with 13 tasks
19/03/29 13:23:01 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:01 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 103, localhost, executor driver, partition 1, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:01 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 104, localhost, executor driver, partition 2, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:01 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 105, localhost, executor driver, partition 3, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:01 INFO Executor: Running task 0.0 in stage 8.0 (TID 102)
19/03/29 13:23:01 INFO Executor: Running task 1.0 in stage 8.0 (TID 103)
19/03/29 13:23:01 INFO Executor: Running task 2.0 in stage 8.0 (TID 104)
19/03/29 13:23:01 INFO Executor: Running task 3.0 in stage 8.0 (TID 105)
19/03/29 13:23:01 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 402653184-536870912, partition values: [empty row]
19/03/29 13:23:01 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 0-134217728, partition values: [empty row]
19/03/29 13:23:01 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 268435456-402653184, partition values: [empty row]
19/03/29 13:23:01 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 134217728-268435456, partition values: [empty row]
19/03/29 13:23:01 INFO CodeGenerator: Code generated in 33.301532 ms
19/03/29 13:23:04 INFO ContextCleaner: Cleaned accumulator 2648
19/03/29 13:23:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:50747 in memory (size: 4.8 KB, free: 912.2 MB)
19/03/29 13:23:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.2 MB)
19/03/29 13:23:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.3 MB)
19/03/29 13:23:24 INFO MemoryStore: Block rdd_31_3 stored as values in memory (estimated size 64.0 MB, free 847.9 MB)
19/03/29 13:23:24 INFO BlockManagerInfo: Added rdd_31_3 in memory on 127.0.0.1:50747 (size: 64.0 MB, free: 848.2 MB)
19/03/29 13:23:24 INFO CodeGenerator: Code generated in 9.716465 ms
19/03/29 13:23:24 INFO CodeGenerator: Code generated in 67.038804 ms
19/03/29 13:23:25 INFO MemoryStore: Block rdd_31_2 stored as values in memory (estimated size 65.1 MB, free 782.9 MB)
19/03/29 13:23:25 INFO BlockManagerInfo: Added rdd_31_2 in memory on 127.0.0.1:50747 (size: 65.1 MB, free: 783.2 MB)
19/03/29 13:23:25 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 65.2 MB, free 717.7 MB)
19/03/29 13:23:25 INFO BlockManagerInfo: Added rdd_31_1 in memory on 127.0.0.1:50747 (size: 65.2 MB, free: 718.0 MB)
19/03/29 13:23:25 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 65.3 MB, free 652.4 MB)
19/03/29 13:23:25 INFO BlockManagerInfo: Added rdd_31_0 in memory on 127.0.0.1:50747 (size: 65.3 MB, free: 652.8 MB)
19/03/29 13:23:25 INFO Executor: Finished task 3.0 in stage 8.0 (TID 105). 2893 bytes result sent to driver
19/03/29 13:23:25 INFO Executor: Finished task 2.0 in stage 8.0 (TID 104). 2893 bytes result sent to driver
19/03/29 13:23:25 INFO Executor: Finished task 1.0 in stage 8.0 (TID 103). 2893 bytes result sent to driver
19/03/29 13:23:25 INFO Executor: Finished task 0.0 in stage 8.0 (TID 102). 2806 bytes result sent to driver
19/03/29 13:23:25 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 106, localhost, executor driver, partition 4, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:25 INFO Executor: Running task 4.0 in stage 8.0 (TID 106)
19/03/29 13:23:25 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 107, localhost, executor driver, partition 5, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:25 INFO Executor: Running task 5.0 in stage 8.0 (TID 107)
19/03/29 13:23:25 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 108, localhost, executor driver, partition 6, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:25 INFO Executor: Running task 6.0 in stage 8.0 (TID 108)
19/03/29 13:23:25 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 109, localhost, executor driver, partition 7, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:25 INFO Executor: Running task 7.0 in stage 8.0 (TID 109)
19/03/29 13:23:25 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 104) in 23375 ms on localhost (executor driver) (1/13)
19/03/29 13:23:25 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 102) in 23388 ms on localhost (executor driver) (2/13)
19/03/29 13:23:25 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 805306368-939524096, partition values: [empty row]
19/03/29 13:23:25 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 105) in 23375 ms on localhost (executor driver) (3/13)
19/03/29 13:23:25 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 671088640-805306368, partition values: [empty row]
19/03/29 13:23:25 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 103) in 23375 ms on localhost (executor driver) (4/13)
19/03/29 13:23:25 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 536870912-671088640, partition values: [empty row]
19/03/29 13:23:25 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 939524096-1073741824, partition values: [empty row]
19/03/29 13:23:47 INFO MemoryStore: Block rdd_31_7 stored as values in memory (estimated size 66.7 MB, free 585.7 MB)
19/03/29 13:23:47 INFO BlockManagerInfo: Added rdd_31_7 in memory on 127.0.0.1:50747 (size: 66.7 MB, free: 586.0 MB)
19/03/29 13:23:47 INFO Executor: Finished task 7.0 in stage 8.0 (TID 109). 2893 bytes result sent to driver
19/03/29 13:23:47 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 110, localhost, executor driver, partition 8, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:47 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 109) in 22599 ms on localhost (executor driver) (5/13)
19/03/29 13:23:47 INFO Executor: Running task 8.0 in stage 8.0 (TID 110)
19/03/29 13:23:47 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1073741824-1207959552, partition values: [empty row]
19/03/29 13:23:47 INFO MemoryStore: Block rdd_31_4 stored as values in memory (estimated size 68.8 MB, free 516.9 MB)
19/03/29 13:23:47 INFO BlockManagerInfo: Added rdd_31_4 in memory on 127.0.0.1:50747 (size: 68.8 MB, free: 517.2 MB)
19/03/29 13:23:47 INFO Executor: Finished task 4.0 in stage 8.0 (TID 106). 2806 bytes result sent to driver
19/03/29 13:23:47 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 111, localhost, executor driver, partition 9, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:47 INFO Executor: Running task 9.0 in stage 8.0 (TID 111)
19/03/29 13:23:47 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 106) in 22669 ms on localhost (executor driver) (6/13)
19/03/29 13:23:47 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1207959552-1342177280, partition values: [empty row]
19/03/29 13:23:47 INFO MemoryStore: Block rdd_31_5 stored as values in memory (estimated size 67.7 MB, free 449.2 MB)
19/03/29 13:23:47 INFO BlockManagerInfo: Added rdd_31_5 in memory on 127.0.0.1:50747 (size: 67.7 MB, free: 449.5 MB)
19/03/29 13:23:48 INFO Executor: Finished task 5.0 in stage 8.0 (TID 107). 2806 bytes result sent to driver
19/03/29 13:23:48 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 112, localhost, executor driver, partition 10, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:48 INFO Executor: Running task 10.0 in stage 8.0 (TID 112)
19/03/29 13:23:48 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 107) in 22768 ms on localhost (executor driver) (7/13)
19/03/29 13:23:48 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1342177280-1476395008, partition values: [empty row]
19/03/29 13:23:48 INFO MemoryStore: Block rdd_31_6 stored as values in memory (estimated size 69.3 MB, free 379.9 MB)
19/03/29 13:23:48 INFO BlockManagerInfo: Added rdd_31_6 in memory on 127.0.0.1:50747 (size: 69.3 MB, free: 380.2 MB)
19/03/29 13:23:48 INFO Executor: Finished task 6.0 in stage 8.0 (TID 108). 2806 bytes result sent to driver
19/03/29 13:23:48 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 113, localhost, executor driver, partition 11, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:23:48 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 108) in 23016 ms on localhost (executor driver) (8/13)
19/03/29 13:23:48 INFO Executor: Running task 11.0 in stage 8.0 (TID 113)
19/03/29 13:23:48 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1476395008-1610612736, partition values: [empty row]
19/03/29 13:24:15 INFO MemoryStore: Block rdd_31_11 stored as values in memory (estimated size 65.7 MB, free 314.2 MB)
19/03/29 13:24:15 INFO BlockManagerInfo: Added rdd_31_11 in memory on 127.0.0.1:50747 (size: 65.7 MB, free: 314.5 MB)
19/03/29 13:24:15 INFO Executor: Finished task 11.0 in stage 8.0 (TID 113). 2893 bytes result sent to driver
19/03/29 13:24:15 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 114, localhost, executor driver, partition 12, PROCESS_LOCAL, 6599 bytes)
19/03/29 13:24:15 INFO Executor: Running task 12.0 in stage 8.0 (TID 114)
19/03/29 13:24:15 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 113) in 27242 ms on localhost (executor driver) (9/13)
19/03/29 13:24:15 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1610612736-1610667208, partition values: [empty row]
19/03/29 13:24:15 INFO MemoryStore: Block rdd_31_12 stored as values in memory (estimated size 36.9 KB, free 314.2 MB)
19/03/29 13:24:15 INFO BlockManagerInfo: Added rdd_31_12 in memory on 127.0.0.1:50747 (size: 36.9 KB, free: 314.5 MB)
19/03/29 13:24:15 INFO Executor: Finished task 12.0 in stage 8.0 (TID 114). 2806 bytes result sent to driver
19/03/29 13:24:15 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 114) in 411 ms on localhost (executor driver) (10/13)
19/03/29 13:24:19 INFO MemoryStore: Block rdd_31_10 stored as values in memory (estimated size 66.6 MB, free 247.6 MB)
19/03/29 13:24:19 INFO BlockManagerInfo: Added rdd_31_10 in memory on 127.0.0.1:50747 (size: 66.6 MB, free: 247.9 MB)
19/03/29 13:24:19 INFO Executor: Finished task 10.0 in stage 8.0 (TID 112). 2806 bytes result sent to driver
19/03/29 13:24:19 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 112) in 31946 ms on localhost (executor driver) (11/13)
19/03/29 13:24:20 INFO MemoryStore: Block rdd_31_8 stored as values in memory (estimated size 64.2 MB, free 183.4 MB)
19/03/29 13:24:20 INFO BlockManagerInfo: Added rdd_31_8 in memory on 127.0.0.1:50747 (size: 64.2 MB, free: 183.7 MB)
19/03/29 13:24:20 INFO Executor: Finished task 8.0 in stage 8.0 (TID 110). 2806 bytes result sent to driver
19/03/29 13:24:20 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 110) in 32247 ms on localhost (executor driver) (12/13)
19/03/29 13:24:21 INFO MemoryStore: Block rdd_31_9 stored as values in memory (estimated size 65.3 MB, free 118.1 MB)
19/03/29 13:24:21 INFO BlockManagerInfo: Added rdd_31_9 in memory on 127.0.0.1:50747 (size: 65.3 MB, free: 118.4 MB)
19/03/29 13:24:21 INFO Executor: Finished task 9.0 in stage 8.0 (TID 111). 2806 bytes result sent to driver
19/03/29 13:24:21 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 111) in 33289 ms on localhost (executor driver) (13/13)
19/03/29 13:24:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/03/29 13:24:21 INFO DAGScheduler: ShuffleMapStage 8 (sql at NativeMethodAccessorImpl.java:0) finished in 79.346 s
19/03/29 13:24:21 INFO DAGScheduler: looking for newly runnable stages
19/03/29 13:24:21 INFO DAGScheduler: running: Set()
19/03/29 13:24:21 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/03/29 13:24:21 INFO DAGScheduler: failed: Set()
19/03/29 13:24:21 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 13:24:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 118.1 MB)
19/03/29 13:24:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 118.0 MB)
19/03/29 13:24:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:50747 (size: 3.7 KB, free: 118.4 MB)
19/03/29 13:24:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
19/03/29 13:24:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
19/03/29 13:24:21 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/03/29 13:24:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 115, localhost, executor driver, partition 0, ANY, 5953 bytes)
19/03/29 13:24:21 INFO Executor: Running task 0.0 in stage 9.0 (TID 115)
19/03/29 13:24:21 INFO ShuffleBlockFetcherIterator: Getting 13 non-empty blocks out of 13 blocks
19/03/29 13:24:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
19/03/29 13:24:21 INFO Executor: Finished task 0.0 in stage 9.0 (TID 115). 1865 bytes result sent to driver
19/03/29 13:24:21 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 115) in 296 ms on localhost (executor driver) (1/1)
19/03/29 13:24:21 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/03/29 13:24:21 INFO DAGScheduler: ResultStage 9 (sql at NativeMethodAccessorImpl.java:0) finished in 0.296 s
19/03/29 13:24:21 INFO DAGScheduler: Job 8 finished: sql at NativeMethodAccessorImpl.java:0, took 79.970816 s
19/03/29 13:24:21 INFO CodeGenerator: Code generated in 28.997772 ms
19/03/29 13:24:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `chicago_raw`
19/03/29 13:24:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/03/29 13:24:22 INFO DAGScheduler: Registering RDD 41 (collect at utils.scala:204)
19/03/29 13:24:22 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/03/29 13:24:22 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:204)
19/03/29 13:24:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/03/29 13:24:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/03/29 13:24:22 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/03/29 13:24:22 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 36.3 KB, free 118.0 MB)
19/03/29 13:24:22 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.1 KB, free 118.0 MB)
19/03/29 13:24:22 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:50747 (size: 15.1 KB, free: 118.4 MB)
19/03/29 13:24:22 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
19/03/29 13:24:22 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204)
19/03/29 13:24:22 INFO TaskSchedulerImpl: Adding task set 10.0 with 13 tasks
19/03/29 13:24:22 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO Executor: Running task 0.0 in stage 10.0 (TID 116)
19/03/29 13:24:22 INFO Executor: Running task 1.0 in stage 10.0 (TID 117)
19/03/29 13:24:22 INFO Executor: Running task 2.0 in stage 10.0 (TID 118)
19/03/29 13:24:22 INFO Executor: Running task 3.0 in stage 10.0 (TID 119)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_1 locally
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_2 locally
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_3 locally
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_0 locally
19/03/29 13:24:22 INFO Executor: Finished task 1.0 in stage 10.0 (TID 117). 2098 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 120, localhost, executor driver, partition 4, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 117) in 70 ms on localhost (executor driver) (1/13)
19/03/29 13:24:22 INFO Executor: Finished task 0.0 in stage 10.0 (TID 116). 2098 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 121, localhost, executor driver, partition 5, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 116) in 80 ms on localhost (executor driver) (2/13)
19/03/29 13:24:22 INFO Executor: Running task 5.0 in stage 10.0 (TID 121)
19/03/29 13:24:22 INFO Executor: Finished task 2.0 in stage 10.0 (TID 118). 2098 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 122, localhost, executor driver, partition 6, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 118) in 80 ms on localhost (executor driver) (3/13)
19/03/29 13:24:22 INFO Executor: Running task 6.0 in stage 10.0 (TID 122)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_5 locally
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_6 locally
19/03/29 13:24:22 INFO Executor: Finished task 3.0 in stage 10.0 (TID 119). 2098 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 123, localhost, executor driver, partition 7, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 119) in 109 ms on localhost (executor driver) (4/13)
19/03/29 13:24:22 INFO Executor: Finished task 5.0 in stage 10.0 (TID 121). 2188 bytes result sent to driver
19/03/29 13:24:22 INFO Executor: Running task 7.0 in stage 10.0 (TID 123)
19/03/29 13:24:22 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 124, localhost, executor driver, partition 8, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 121) in 41 ms on localhost (executor driver) (5/13)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_7 locally
19/03/29 13:24:22 INFO Executor: Running task 8.0 in stage 10.0 (TID 124)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_8 locally
19/03/29 13:24:22 INFO Executor: Running task 4.0 in stage 10.0 (TID 120)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_4 locally
19/03/29 13:24:22 INFO Executor: Finished task 6.0 in stage 10.0 (TID 122). 2011 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 125, localhost, executor driver, partition 9, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO Executor: Running task 9.0 in stage 10.0 (TID 125)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 122) in 83 ms on localhost (executor driver) (6/13)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_9 locally
19/03/29 13:24:22 INFO Executor: Finished task 4.0 in stage 10.0 (TID 120). 2098 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 126, localhost, executor driver, partition 10, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO Executor: Finished task 7.0 in stage 10.0 (TID 123). 1932 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 11.0 in stage 10.0 (TID 127, localhost, executor driver, partition 11, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 120) in 113 ms on localhost (executor driver) (7/13)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 123) in 81 ms on localhost (executor driver) (8/13)
19/03/29 13:24:22 INFO Executor: Running task 11.0 in stage 10.0 (TID 127)
19/03/29 13:24:22 INFO Executor: Running task 10.0 in stage 10.0 (TID 126)
19/03/29 13:24:22 INFO Executor: Finished task 8.0 in stage 10.0 (TID 124). 2011 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Starting task 12.0 in stage 10.0 (TID 128, localhost, executor driver, partition 12, PROCESS_LOCAL, 6591 bytes)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 124) in 78 ms on localhost (executor driver) (9/13)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_11 locally
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_10 locally
19/03/29 13:24:22 INFO Executor: Running task 12.0 in stage 10.0 (TID 128)
19/03/29 13:24:22 INFO BlockManager: Found block rdd_31_12 locally
19/03/29 13:24:22 INFO Executor: Finished task 9.0 in stage 10.0 (TID 125). 2011 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 125) in 71 ms on localhost (executor driver) (10/13)
19/03/29 13:24:22 INFO Executor: Finished task 10.0 in stage 10.0 (TID 126). 2188 bytes result sent to driver
19/03/29 13:24:22 INFO Executor: Finished task 11.0 in stage 10.0 (TID 127). 2011 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 126) in 79 ms on localhost (executor driver) (11/13)
19/03/29 13:24:22 INFO TaskSetManager: Finished task 11.0 in stage 10.0 (TID 127) in 73 ms on localhost (executor driver) (12/13)
19/03/29 13:24:22 INFO Executor: Finished task 12.0 in stage 10.0 (TID 128). 2019 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Finished task 12.0 in stage 10.0 (TID 128) in 81 ms on localhost (executor driver) (13/13)
19/03/29 13:24:22 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/03/29 13:24:22 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:204) finished in 0.272 s
19/03/29 13:24:22 INFO DAGScheduler: looking for newly runnable stages
19/03/29 13:24:22 INFO DAGScheduler: running: Set()
19/03/29 13:24:22 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/03/29 13:24:22 INFO DAGScheduler: failed: Set()
19/03/29 13:24:22 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[44] at collect at utils.scala:204), which has no missing parents
19/03/29 13:24:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 118.0 MB)
19/03/29 13:24:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 118.0 MB)
19/03/29 13:24:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:50747 (size: 3.7 KB, free: 118.3 MB)
19/03/29 13:24:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
19/03/29 13:24:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[44] at collect at utils.scala:204)
19/03/29 13:24:22 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/03/29 13:24:22 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 129, localhost, executor driver, partition 0, ANY, 5945 bytes)
19/03/29 13:24:22 INFO Executor: Running task 0.0 in stage 11.0 (TID 129)
19/03/29 13:24:22 INFO ShuffleBlockFetcherIterator: Getting 13 non-empty blocks out of 13 blocks
19/03/29 13:24:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/03/29 13:24:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 129). 1963 bytes result sent to driver
19/03/29 13:24:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 129) in 10 ms on localhost (executor driver) (1/1)
19/03/29 13:24:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/03/29 13:24:22 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:204) finished in 0.010 s
19/03/29 13:24:22 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.325824 s
19/03/29 13:24:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw` AS `zzz1`
WHERE (0 = 1)
19/03/29 13:35:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 1
19/03/29 13:35:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 1
19/03/29 13:35:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 1
19/03/29 13:35:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 1
19/03/29 13:35:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/03/29 13:35:29 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
19/03/29 13:35:29 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/03/29 13:35:29 INFO DAGScheduler: Parents of final stage: List()
19/03/29 13:35:29 INFO DAGScheduler: Missing parents: List()
19/03/29 13:35:29 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:204), which has no missing parents
19/03/29 13:35:29 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.3 KB, free 118.0 MB)
19/03/29 13:35:29 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 13.1 KB, free 117.9 MB)
19/03/29 13:35:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:50747 (size: 13.1 KB, free: 118.3 MB)
19/03/29 13:35:29 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
19/03/29 13:35:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at collect at utils.scala:204)
19/03/29 13:35:29 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/03/29 13:35:29 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 6517 bytes)
19/03/29 13:35:29 INFO Executor: Running task 0.0 in stage 12.0 (TID 130)
19/03/29 13:35:29 INFO BlockManager: Found block rdd_31_0 locally
19/03/29 13:35:29 INFO CodeGenerator: Code generated in 78.534623 ms
19/03/29 13:35:29 WARN Executor: 1 block locks were not released by TID = 130:
[rdd_31_0]
19/03/29 13:35:29 INFO Executor: Finished task 0.0 in stage 12.0 (TID 130). 1689 bytes result sent to driver
19/03/29 13:35:29 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 130) in 372 ms on localhost (executor driver) (1/1)
19/03/29 13:35:29 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.374 s
19/03/29 13:35:29 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/03/29 13:35:29 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.514334 s
19/03/29 13:35:30 INFO CodeGenerator: Code generated in 162.120855 ms
19/03/29 13:35:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 1
19/03/29 13:44:28 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `hukforgavi`) `arxvhplofm`
LIMIT 6
19/03/29 13:46:09 INFO ContextCleaner: Cleaned accumulator 2659
19/03/29 13:46:10 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:50747 in memory (size: 13.1 KB, free: 118.3 MB)
19/03/29 13:46:10 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:50747 in memory (size: 15.1 KB, free: 118.4 MB)
19/03/29 13:46:10 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:50747 in memory (size: 3.7 KB, free: 118.4 MB)
19/03/29 13:46:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:50747 in memory (size: 3.7 KB, free: 118.4 MB)
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3045
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3046
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3047
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3048
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3049
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3050
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3051
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3052
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3053
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3054
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3055
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3056
19/03/29 13:46:10 INFO ContextCleaner: Cleaned accumulator 3057
19/03/29 13:46:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `dyxlowmajk`) `xenwlmjkvw`) `lemgfhzchu`
WHERE (`Year` = 2005.0)
19/03/29 13:46:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `oyisrhngsv`) `dkhtkklodb`) `gdwabbwwrc`
WHERE (`Year` = 2005.0)
19/03/29 13:46:11 INFO ContextCleaner: Cleaned shuffle 1
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 3442
19/03/29 13:46:11 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:50747 in memory (size: 15.0 KB, free: 118.4 MB)
19/03/29 13:46:11 INFO ContextCleaner: Cleaned shuffle 0
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2660
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2658
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2657
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2656
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2655
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2654
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2653
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2652
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2651
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2650
19/03/29 13:46:11 INFO ContextCleaner: Cleaned accumulator 2649
19/03/29 13:55:26 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@17af5b91,BlockManagerId(driver, 127.0.0.1, 50747, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
19/03/29 13:55:35 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
19/03/29 14:05:29 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `fgeicvbolq`) `ljtamcbcca`
LIMIT 6
19/03/29 14:05:29 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `ybytutqkpy`) `ctdppbctvb`
LIMIT 6
19/03/29 14:06:45 INFO SparkSqlParser: Parsing command: SELECT `ID`
FROM (SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `qsvmijpiie`) `flfkngudya`) `jpalifrjxa`
19/03/29 14:06:45 INFO SparkSqlParser: Parsing command: SELECT `ID`
FROM (SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `rqqiievigl`) `uymwoqubwq`) `wffjvjdguu`
19/03/29 14:06:52 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `qtsettzwby`) `qothypnjfe`
19/03/29 14:06:52 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `snrxhkpoog`) `ycruixtbzy`
19/03/29 14:06:55 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `ljtnkwxkun`) `jhugydyaeg`
19/03/29 14:07:34 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `lpvkbbytll`) `cpkgczfhhs`
19/03/29 14:14:34 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `ehqypmlgfl`) `hihqfltfkn`
19/03/29 14:15:03 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `fskcdigoev`) `rfhjvvbidm`
19/03/29 14:15:09 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `xwhjyxuowf`) `djdsgldfiy`
19/03/29 14:15:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 14:15:29 INFO HiveMetaStore: 0: get_database: default
19/03/29 14:15:29 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 14:15:29 INFO HiveMetaStore: 0: get_database: default
19/03/29 14:15:29 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 14:15:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 14:15:29 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 14:15:30 INFO SparkContext: Starting job: collect at utils.scala:44
19/03/29 14:15:30 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 1 output partitions
19/03/29 14:15:30 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:44)
19/03/29 14:15:30 INFO DAGScheduler: Parents of final stage: List()
19/03/29 14:15:30 INFO DAGScheduler: Missing parents: List()
19/03/29 14:15:30 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[52] at map at utils.scala:41), which has no missing parents
19/03/29 14:15:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.7 KB, free 118.1 MB)
19/03/29 14:15:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 118.1 MB)
19/03/29 14:15:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:50747 (size: 4.6 KB, free: 118.4 MB)
19/03/29 14:15:30 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
19/03/29 14:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[52] at map at utils.scala:41)
19/03/29 14:15:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/03/29 14:15:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 131, localhost, executor driver, partition 0, PROCESS_LOCAL, 6361 bytes)
19/03/29 14:15:30 INFO Executor: Running task 0.0 in stage 13.0 (TID 131)
19/03/29 14:15:31 INFO Executor: Finished task 0.0 in stage 13.0 (TID 131). 1163 bytes result sent to driver
19/03/29 14:15:31 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 131) in 57 ms on localhost (executor driver) (1/1)
19/03/29 14:15:31 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/03/29 14:15:31 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:44) finished in 0.057 s
19/03/29 14:15:31 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0.222125 s
19/03/29 14:15:31 INFO SparkSqlParser: Parsing command: DROP TABLE `chicago_raw`
19/03/29 14:15:31 INFO SparkSqlParser: Parsing command: `chicago_raw`
19/03/29 14:15:31 INFO MapPartitionsRDD: Removing RDD 31 from persistence list
19/03/29 14:15:31 INFO BlockManager: Removing RDD 31
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 238.7 KB, free 911.8 MB)
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.3 KB, free 911.7 MB)
19/03/29 14:15:33 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.2 MB)
19/03/29 14:15:33 INFO SparkContext: Created broadcast 19 from csv at NativeMethodAccessorImpl.java:0
19/03/29 14:15:33 INFO FileInputFormat: Total input paths to process : 1
19/03/29 14:15:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 14:15:33 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 14:15:33 INFO DAGScheduler: Final stage: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:33 INFO DAGScheduler: Parents of final stage: List()
19/03/29 14:15:33 INFO DAGScheduler: Missing parents: List()
19/03/29 14:15:33 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.5 KB, free 911.7 MB)
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.7 MB)
19/03/29 14:15:33 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.2 MB)
19/03/29 14:15:33 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
19/03/29 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:33 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/03/29 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 6066 bytes)
19/03/29 14:15:33 INFO Executor: Running task 0.0 in stage 14.0 (TID 132)
19/03/29 14:15:33 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 14:15:33 INFO Executor: Finished task 0.0 in stage 14.0 (TID 132). 1206 bytes result sent to driver
19/03/29 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 132) in 129 ms on localhost (executor driver) (1/1)
19/03/29 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/03/29 14:15:33 INFO DAGScheduler: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0) finished in 0.129 s
19/03/29 14:15:33 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0.197800 s
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 238.7 KB, free 911.5 MB)
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.3 KB, free 911.5 MB)
19/03/29 14:15:33 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:50747 (size: 23.3 KB, free: 912.2 MB)
19/03/29 14:15:33 INFO SparkContext: Created broadcast 21 from csv at NativeMethodAccessorImpl.java:0
19/03/29 14:15:33 INFO FileInputFormat: Total input paths to process : 1
19/03/29 14:15:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 14:15:33 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/03/29 14:15:33 INFO DAGScheduler: Final stage: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:33 INFO DAGScheduler: Parents of final stage: List()
19/03/29 14:15:33 INFO DAGScheduler: Missing parents: List()
19/03/29 14:15:33 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[59] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 3.5 KB, free 911.5 MB)
19/03/29 14:15:33 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.5 MB)
19/03/29 14:15:33 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:50747 (size: 2.1 KB, free: 912.2 MB)
19/03/29 14:15:33 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
19/03/29 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[59] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:33 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/03/29 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 6066 bytes)
19/03/29 14:15:33 INFO Executor: Running task 0.0 in stage 15.0 (TID 133)
19/03/29 14:15:33 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 14:15:33 INFO Executor: Finished task 0.0 in stage 15.0 (TID 133). 1206 bytes result sent to driver
19/03/29 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 133) in 24 ms on localhost (executor driver) (1/1)
19/03/29 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/03/29 14:15:33 INFO DAGScheduler: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0) finished in 0.026 s
19/03/29 14:15:33 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.070291 s
19/03/29 14:15:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/03/29 14:15:34 INFO DAGScheduler: Got job 14 (csv at NativeMethodAccessorImpl.java:0) with 48 output partitions
19/03/29 14:15:34 INFO DAGScheduler: Final stage: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:34 INFO DAGScheduler: Parents of final stage: List()
19/03/29 14:15:34 INFO DAGScheduler: Missing parents: List()
19/03/29 14:15:34 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[60] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/03/29 14:15:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.5 KB, free 911.5 MB)
19/03/29 14:15:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.8 KB, free 911.5 MB)
19/03/29 14:15:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:50747 (size: 4.8 KB, free: 912.2 MB)
19/03/29 14:15:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
19/03/29 14:15:34 INFO DAGScheduler: Submitting 48 missing tasks from ResultStage 16 (MapPartitionsRDD[60] at csv at NativeMethodAccessorImpl.java:0)
19/03/29 14:15:34 INFO TaskSchedulerImpl: Adding task set 16.0 with 48 tasks
19/03/29 14:15:34 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:34 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:34 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:34 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:34 INFO Executor: Running task 0.0 in stage 16.0 (TID 134)
19/03/29 14:15:34 INFO Executor: Running task 1.0 in stage 16.0 (TID 135)
19/03/29 14:15:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:0+33554432
19/03/29 14:15:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:33554432+33554432
19/03/29 14:15:34 INFO Executor: Running task 2.0 in stage 16.0 (TID 136)
19/03/29 14:15:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:67108864+33554432
19/03/29 14:15:34 INFO Executor: Running task 3.0 in stage 16.0 (TID 137)
19/03/29 14:15:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:100663296+33554432
19/03/29 14:15:44 INFO ContextCleaner: Cleaned accumulator 3492
19/03/29 14:15:44 INFO ContextCleaner: Cleaned accumulator 3491
19/03/29 14:15:44 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:50747 in memory (size: 4.6 KB, free: 912.2 MB)
19/03/29 14:15:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 14:15:44 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:50747 in memory (size: 2.1 KB, free: 912.2 MB)
19/03/29 14:15:57 INFO Executor: Finished task 1.0 in stage 16.0 (TID 135). 1402 bytes result sent to driver
19/03/29 14:15:58 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:58 INFO Executor: Running task 4.0 in stage 16.0 (TID 138)
19/03/29 14:15:58 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 135) in 23734 ms on localhost (executor driver) (1/48)
19/03/29 14:15:58 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:134217728+33554432
19/03/29 14:15:58 INFO Executor: Finished task 2.0 in stage 16.0 (TID 136). 1402 bytes result sent to driver
19/03/29 14:15:58 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 139, localhost, executor driver, partition 5, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:58 INFO Executor: Running task 5.0 in stage 16.0 (TID 139)
19/03/29 14:15:58 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 136) in 24000 ms on localhost (executor driver) (2/48)
19/03/29 14:15:58 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:167772160+33554432
19/03/29 14:15:59 INFO Executor: Finished task 0.0 in stage 16.0 (TID 134). 1402 bytes result sent to driver
19/03/29 14:15:59 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 140, localhost, executor driver, partition 6, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:15:59 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 134) in 25608 ms on localhost (executor driver) (3/48)
19/03/29 14:15:59 INFO Executor: Running task 6.0 in stage 16.0 (TID 140)
19/03/29 14:15:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:201326592+33554432
19/03/29 14:16:04 INFO Executor: Finished task 3.0 in stage 16.0 (TID 137). 1402 bytes result sent to driver
19/03/29 14:16:04 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 141, localhost, executor driver, partition 7, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:04 INFO Executor: Running task 7.0 in stage 16.0 (TID 141)
19/03/29 14:16:04 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 137) in 30091 ms on localhost (executor driver) (4/48)
19/03/29 14:16:04 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:234881024+33554432
19/03/29 14:16:14 INFO Executor: Finished task 5.0 in stage 16.0 (TID 139). 1402 bytes result sent to driver
19/03/29 14:16:14 INFO TaskSetManager: Starting task 8.0 in stage 16.0 (TID 142, localhost, executor driver, partition 8, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:14 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 139) in 16007 ms on localhost (executor driver) (5/48)
19/03/29 14:16:14 INFO Executor: Running task 8.0 in stage 16.0 (TID 142)
19/03/29 14:16:14 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:268435456+33554432
19/03/29 14:16:20 INFO Executor: Finished task 4.0 in stage 16.0 (TID 138). 1489 bytes result sent to driver
19/03/29 14:16:20 INFO TaskSetManager: Starting task 9.0 in stage 16.0 (TID 143, localhost, executor driver, partition 9, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:20 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 138) in 22507 ms on localhost (executor driver) (6/48)
19/03/29 14:16:20 INFO Executor: Running task 9.0 in stage 16.0 (TID 143)
19/03/29 14:16:20 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:301989888+33554432
19/03/29 14:16:20 INFO Executor: Finished task 7.0 in stage 16.0 (TID 141). 1402 bytes result sent to driver
19/03/29 14:16:20 INFO TaskSetManager: Starting task 10.0 in stage 16.0 (TID 144, localhost, executor driver, partition 10, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:20 INFO Executor: Running task 10.0 in stage 16.0 (TID 144)
19/03/29 14:16:20 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 141) in 16412 ms on localhost (executor driver) (7/48)
19/03/29 14:16:20 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:335544320+33554432
19/03/29 14:16:24 INFO Executor: Finished task 6.0 in stage 16.0 (TID 140). 1402 bytes result sent to driver
19/03/29 14:16:24 INFO TaskSetManager: Starting task 11.0 in stage 16.0 (TID 145, localhost, executor driver, partition 11, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:24 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 140) in 24585 ms on localhost (executor driver) (8/48)
19/03/29 14:16:24 INFO Executor: Running task 11.0 in stage 16.0 (TID 145)
19/03/29 14:16:24 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:369098752+33554432
19/03/29 14:16:31 INFO Executor: Finished task 8.0 in stage 16.0 (TID 142). 1402 bytes result sent to driver
19/03/29 14:16:31 INFO TaskSetManager: Starting task 12.0 in stage 16.0 (TID 146, localhost, executor driver, partition 12, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:31 INFO Executor: Running task 12.0 in stage 16.0 (TID 146)
19/03/29 14:16:31 INFO TaskSetManager: Finished task 8.0 in stage 16.0 (TID 142) in 17495 ms on localhost (executor driver) (9/48)
19/03/29 14:16:31 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:402653184+33554432
19/03/29 14:16:37 INFO Executor: Finished task 9.0 in stage 16.0 (TID 143). 1402 bytes result sent to driver
19/03/29 14:16:37 INFO TaskSetManager: Starting task 13.0 in stage 16.0 (TID 147, localhost, executor driver, partition 13, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:37 INFO TaskSetManager: Finished task 9.0 in stage 16.0 (TID 143) in 16671 ms on localhost (executor driver) (10/48)
19/03/29 14:16:37 INFO Executor: Running task 13.0 in stage 16.0 (TID 147)
19/03/29 14:16:37 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:436207616+33554432
19/03/29 14:16:41 INFO Executor: Finished task 11.0 in stage 16.0 (TID 145). 1402 bytes result sent to driver
19/03/29 14:16:41 INFO TaskSetManager: Starting task 14.0 in stage 16.0 (TID 148, localhost, executor driver, partition 14, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:41 INFO TaskSetManager: Finished task 11.0 in stage 16.0 (TID 145) in 16697 ms on localhost (executor driver) (11/48)
19/03/29 14:16:41 INFO Executor: Running task 14.0 in stage 16.0 (TID 148)
19/03/29 14:16:41 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:469762048+33554432
19/03/29 14:16:45 INFO Executor: Finished task 10.0 in stage 16.0 (TID 144). 1402 bytes result sent to driver
19/03/29 14:16:45 INFO TaskSetManager: Starting task 15.0 in stage 16.0 (TID 149, localhost, executor driver, partition 15, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:45 INFO TaskSetManager: Finished task 10.0 in stage 16.0 (TID 144) in 24920 ms on localhost (executor driver) (12/48)
19/03/29 14:16:45 INFO Executor: Running task 15.0 in stage 16.0 (TID 149)
19/03/29 14:16:45 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:503316480+33554432
19/03/29 14:16:51 INFO Executor: Finished task 12.0 in stage 16.0 (TID 146). 1402 bytes result sent to driver
19/03/29 14:16:51 INFO TaskSetManager: Starting task 16.0 in stage 16.0 (TID 150, localhost, executor driver, partition 16, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:51 INFO Executor: Running task 16.0 in stage 16.0 (TID 150)
19/03/29 14:16:51 INFO TaskSetManager: Finished task 12.0 in stage 16.0 (TID 146) in 19524 ms on localhost (executor driver) (13/48)
19/03/29 14:16:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:536870912+33554432
19/03/29 14:16:52 INFO Executor: Finished task 13.0 in stage 16.0 (TID 147). 1489 bytes result sent to driver
19/03/29 14:16:52 INFO TaskSetManager: Starting task 17.0 in stage 16.0 (TID 151, localhost, executor driver, partition 17, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:52 INFO Executor: Running task 17.0 in stage 16.0 (TID 151)
19/03/29 14:16:52 INFO TaskSetManager: Finished task 13.0 in stage 16.0 (TID 147) in 15751 ms on localhost (executor driver) (14/48)
19/03/29 14:16:52 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:570425344+33554432
19/03/29 14:16:59 INFO Executor: Finished task 14.0 in stage 16.0 (TID 148). 1402 bytes result sent to driver
19/03/29 14:16:59 INFO TaskSetManager: Starting task 18.0 in stage 16.0 (TID 152, localhost, executor driver, partition 18, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:16:59 INFO TaskSetManager: Finished task 14.0 in stage 16.0 (TID 148) in 18289 ms on localhost (executor driver) (15/48)
19/03/29 14:16:59 INFO Executor: Running task 18.0 in stage 16.0 (TID 152)
19/03/29 14:16:59 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:603979776+33554432
19/03/29 14:17:03 INFO Executor: Finished task 15.0 in stage 16.0 (TID 149). 1402 bytes result sent to driver
19/03/29 14:17:03 INFO TaskSetManager: Starting task 19.0 in stage 16.0 (TID 153, localhost, executor driver, partition 19, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:03 INFO TaskSetManager: Finished task 15.0 in stage 16.0 (TID 149) in 17616 ms on localhost (executor driver) (16/48)
19/03/29 14:17:03 INFO Executor: Running task 19.0 in stage 16.0 (TID 153)
19/03/29 14:17:03 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:637534208+33554432
19/03/29 14:17:10 INFO Executor: Finished task 16.0 in stage 16.0 (TID 150). 1402 bytes result sent to driver
19/03/29 14:17:10 INFO TaskSetManager: Starting task 20.0 in stage 16.0 (TID 154, localhost, executor driver, partition 20, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:10 INFO TaskSetManager: Finished task 16.0 in stage 16.0 (TID 150) in 19098 ms on localhost (executor driver) (17/48)
19/03/29 14:17:10 INFO Executor: Running task 20.0 in stage 16.0 (TID 154)
19/03/29 14:17:10 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:671088640+33554432
19/03/29 14:17:16 INFO Executor: Finished task 17.0 in stage 16.0 (TID 151). 1402 bytes result sent to driver
19/03/29 14:17:16 INFO TaskSetManager: Starting task 21.0 in stage 16.0 (TID 155, localhost, executor driver, partition 21, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:16 INFO TaskSetManager: Finished task 17.0 in stage 16.0 (TID 151) in 23999 ms on localhost (executor driver) (18/48)
19/03/29 14:17:16 INFO Executor: Running task 21.0 in stage 16.0 (TID 155)
19/03/29 14:17:16 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:704643072+33554432
19/03/29 14:17:17 INFO Executor: Finished task 18.0 in stage 16.0 (TID 152). 1489 bytes result sent to driver
19/03/29 14:17:17 INFO TaskSetManager: Starting task 22.0 in stage 16.0 (TID 156, localhost, executor driver, partition 22, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:17 INFO TaskSetManager: Finished task 18.0 in stage 16.0 (TID 152) in 18189 ms on localhost (executor driver) (19/48)
19/03/29 14:17:17 INFO Executor: Running task 22.0 in stage 16.0 (TID 156)
19/03/29 14:17:17 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:738197504+33554432
19/03/29 14:17:21 INFO Executor: Finished task 19.0 in stage 16.0 (TID 153). 1402 bytes result sent to driver
19/03/29 14:17:21 INFO TaskSetManager: Starting task 23.0 in stage 16.0 (TID 157, localhost, executor driver, partition 23, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:21 INFO TaskSetManager: Finished task 19.0 in stage 16.0 (TID 153) in 17870 ms on localhost (executor driver) (20/48)
19/03/29 14:17:21 INFO Executor: Running task 23.0 in stage 16.0 (TID 157)
19/03/29 14:17:21 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:771751936+33554432
19/03/29 14:17:34 INFO Executor: Finished task 22.0 in stage 16.0 (TID 156). 1492 bytes result sent to driver
19/03/29 14:17:34 INFO TaskSetManager: Starting task 24.0 in stage 16.0 (TID 158, localhost, executor driver, partition 24, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:34 INFO TaskSetManager: Finished task 22.0 in stage 16.0 (TID 156) in 16359 ms on localhost (executor driver) (21/48)
19/03/29 14:17:34 INFO Executor: Running task 24.0 in stage 16.0 (TID 158)
19/03/29 14:17:34 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:805306368+33554432
19/03/29 14:17:35 INFO Executor: Finished task 21.0 in stage 16.0 (TID 155). 1402 bytes result sent to driver
19/03/29 14:17:35 INFO TaskSetManager: Starting task 25.0 in stage 16.0 (TID 159, localhost, executor driver, partition 25, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:35 INFO Executor: Running task 25.0 in stage 16.0 (TID 159)
19/03/29 14:17:35 INFO TaskSetManager: Finished task 21.0 in stage 16.0 (TID 155) in 18902 ms on localhost (executor driver) (22/48)
19/03/29 14:17:35 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:838860800+33554432
19/03/29 14:17:37 INFO Executor: Finished task 23.0 in stage 16.0 (TID 157). 1402 bytes result sent to driver
19/03/29 14:17:37 INFO TaskSetManager: Starting task 26.0 in stage 16.0 (TID 160, localhost, executor driver, partition 26, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:37 INFO TaskSetManager: Finished task 23.0 in stage 16.0 (TID 157) in 16624 ms on localhost (executor driver) (23/48)
19/03/29 14:17:37 INFO Executor: Running task 26.0 in stage 16.0 (TID 160)
19/03/29 14:17:37 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:872415232+33554432
19/03/29 14:17:38 INFO Executor: Finished task 20.0 in stage 16.0 (TID 154). 1402 bytes result sent to driver
19/03/29 14:17:38 INFO TaskSetManager: Starting task 27.0 in stage 16.0 (TID 161, localhost, executor driver, partition 27, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:38 INFO TaskSetManager: Finished task 20.0 in stage 16.0 (TID 154) in 28187 ms on localhost (executor driver) (24/48)
19/03/29 14:17:38 INFO Executor: Running task 27.0 in stage 16.0 (TID 161)
19/03/29 14:17:38 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:905969664+33554432
19/03/29 14:17:51 INFO Executor: Finished task 25.0 in stage 16.0 (TID 159). 1489 bytes result sent to driver
19/03/29 14:17:51 INFO TaskSetManager: Starting task 28.0 in stage 16.0 (TID 162, localhost, executor driver, partition 28, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:51 INFO TaskSetManager: Finished task 25.0 in stage 16.0 (TID 159) in 16008 ms on localhost (executor driver) (25/48)
19/03/29 14:17:51 INFO Executor: Running task 28.0 in stage 16.0 (TID 162)
19/03/29 14:17:51 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:939524096+33554432
19/03/29 14:17:54 INFO Executor: Finished task 26.0 in stage 16.0 (TID 160). 1492 bytes result sent to driver
19/03/29 14:17:54 INFO TaskSetManager: Starting task 29.0 in stage 16.0 (TID 163, localhost, executor driver, partition 29, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:54 INFO TaskSetManager: Finished task 26.0 in stage 16.0 (TID 160) in 16584 ms on localhost (executor driver) (26/48)
19/03/29 14:17:54 INFO Executor: Running task 29.0 in stage 16.0 (TID 163)
19/03/29 14:17:54 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:973078528+33554432
19/03/29 14:17:56 INFO Executor: Finished task 27.0 in stage 16.0 (TID 161). 1402 bytes result sent to driver
19/03/29 14:17:56 INFO TaskSetManager: Starting task 30.0 in stage 16.0 (TID 164, localhost, executor driver, partition 30, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:17:56 INFO TaskSetManager: Finished task 27.0 in stage 16.0 (TID 161) in 17705 ms on localhost (executor driver) (27/48)
19/03/29 14:17:56 INFO Executor: Running task 30.0 in stage 16.0 (TID 164)
19/03/29 14:17:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1006632960+33554432
19/03/29 14:18:01 INFO Executor: Finished task 24.0 in stage 16.0 (TID 158). 1492 bytes result sent to driver
19/03/29 14:18:01 INFO TaskSetManager: Starting task 31.0 in stage 16.0 (TID 165, localhost, executor driver, partition 31, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:01 INFO Executor: Running task 31.0 in stage 16.0 (TID 165)
19/03/29 14:18:01 INFO TaskSetManager: Finished task 24.0 in stage 16.0 (TID 158) in 27855 ms on localhost (executor driver) (28/48)
19/03/29 14:18:01 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1040187392+33554432
19/03/29 14:18:12 INFO Executor: Finished task 30.0 in stage 16.0 (TID 164). 1402 bytes result sent to driver
19/03/29 14:18:12 INFO TaskSetManager: Starting task 32.0 in stage 16.0 (TID 166, localhost, executor driver, partition 32, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:12 INFO TaskSetManager: Finished task 30.0 in stage 16.0 (TID 164) in 16275 ms on localhost (executor driver) (29/48)
19/03/29 14:18:12 INFO Executor: Running task 32.0 in stage 16.0 (TID 166)
19/03/29 14:18:12 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1073741824+33554432
19/03/29 14:18:13 INFO Executor: Finished task 29.0 in stage 16.0 (TID 163). 1402 bytes result sent to driver
19/03/29 14:18:13 INFO TaskSetManager: Starting task 33.0 in stage 16.0 (TID 167, localhost, executor driver, partition 33, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:13 INFO Executor: Running task 33.0 in stage 16.0 (TID 167)
19/03/29 14:18:13 INFO TaskSetManager: Finished task 29.0 in stage 16.0 (TID 163) in 18900 ms on localhost (executor driver) (30/48)
19/03/29 14:18:13 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1107296256+33554432
19/03/29 14:18:14 INFO Executor: Finished task 28.0 in stage 16.0 (TID 162). 1402 bytes result sent to driver
19/03/29 14:18:14 INFO TaskSetManager: Starting task 34.0 in stage 16.0 (TID 168, localhost, executor driver, partition 34, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:14 INFO Executor: Running task 34.0 in stage 16.0 (TID 168)
19/03/29 14:18:14 INFO TaskSetManager: Finished task 28.0 in stage 16.0 (TID 162) in 22915 ms on localhost (executor driver) (31/48)
19/03/29 14:18:14 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1140850688+33554432
19/03/29 14:18:31 INFO Executor: Finished task 31.0 in stage 16.0 (TID 165). 1402 bytes result sent to driver
19/03/29 14:18:31 INFO TaskSetManager: Starting task 35.0 in stage 16.0 (TID 169, localhost, executor driver, partition 35, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:31 INFO TaskSetManager: Finished task 31.0 in stage 16.0 (TID 165) in 29448 ms on localhost (executor driver) (32/48)
19/03/29 14:18:31 INFO Executor: Running task 35.0 in stage 16.0 (TID 169)
19/03/29 14:18:31 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1174405120+33554432
19/03/29 14:18:35 INFO Executor: Finished task 32.0 in stage 16.0 (TID 166). 1489 bytes result sent to driver
19/03/29 14:18:35 INFO TaskSetManager: Starting task 36.0 in stage 16.0 (TID 170, localhost, executor driver, partition 36, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:35 INFO TaskSetManager: Finished task 32.0 in stage 16.0 (TID 166) in 22685 ms on localhost (executor driver) (33/48)
19/03/29 14:18:35 INFO Executor: Running task 36.0 in stage 16.0 (TID 170)
19/03/29 14:18:35 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1207959552+33554432
19/03/29 14:18:35 INFO Executor: Finished task 33.0 in stage 16.0 (TID 167). 1402 bytes result sent to driver
19/03/29 14:18:35 INFO TaskSetManager: Starting task 37.0 in stage 16.0 (TID 171, localhost, executor driver, partition 37, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:35 INFO Executor: Running task 37.0 in stage 16.0 (TID 171)
19/03/29 14:18:35 INFO TaskSetManager: Finished task 33.0 in stage 16.0 (TID 167) in 22564 ms on localhost (executor driver) (34/48)
19/03/29 14:18:35 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1241513984+33554432
19/03/29 14:18:37 INFO Executor: Finished task 34.0 in stage 16.0 (TID 168). 1402 bytes result sent to driver
19/03/29 14:18:37 INFO TaskSetManager: Starting task 38.0 in stage 16.0 (TID 172, localhost, executor driver, partition 38, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:37 INFO TaskSetManager: Finished task 34.0 in stage 16.0 (TID 168) in 22773 ms on localhost (executor driver) (35/48)
19/03/29 14:18:37 INFO Executor: Running task 38.0 in stage 16.0 (TID 172)
19/03/29 14:18:37 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1275068416+33554432
19/03/29 14:18:55 INFO Executor: Finished task 35.0 in stage 16.0 (TID 169). 1492 bytes result sent to driver
19/03/29 14:18:55 INFO TaskSetManager: Starting task 39.0 in stage 16.0 (TID 173, localhost, executor driver, partition 39, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:55 INFO TaskSetManager: Finished task 35.0 in stage 16.0 (TID 169) in 24307 ms on localhost (executor driver) (36/48)
19/03/29 14:18:55 INFO Executor: Running task 39.0 in stage 16.0 (TID 173)
19/03/29 14:18:55 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1308622848+33554432
19/03/29 14:18:56 INFO Executor: Finished task 37.0 in stage 16.0 (TID 171). 1402 bytes result sent to driver
19/03/29 14:18:56 INFO TaskSetManager: Starting task 40.0 in stage 16.0 (TID 174, localhost, executor driver, partition 40, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:56 INFO Executor: Running task 40.0 in stage 16.0 (TID 174)
19/03/29 14:18:56 INFO TaskSetManager: Finished task 37.0 in stage 16.0 (TID 171) in 20579 ms on localhost (executor driver) (37/48)
19/03/29 14:18:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1342177280+33554432
19/03/29 14:18:56 INFO Executor: Finished task 36.0 in stage 16.0 (TID 170). 1402 bytes result sent to driver
19/03/29 14:18:56 INFO TaskSetManager: Starting task 41.0 in stage 16.0 (TID 175, localhost, executor driver, partition 41, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:56 INFO Executor: Running task 41.0 in stage 16.0 (TID 175)
19/03/29 14:18:56 INFO TaskSetManager: Finished task 36.0 in stage 16.0 (TID 170) in 21746 ms on localhost (executor driver) (38/48)
19/03/29 14:18:56 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1375731712+33554432
19/03/29 14:18:57 INFO Executor: Finished task 38.0 in stage 16.0 (TID 172). 1402 bytes result sent to driver
19/03/29 14:18:57 INFO TaskSetManager: Starting task 42.0 in stage 16.0 (TID 176, localhost, executor driver, partition 42, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:18:57 INFO Executor: Running task 42.0 in stage 16.0 (TID 176)
19/03/29 14:18:57 INFO TaskSetManager: Finished task 38.0 in stage 16.0 (TID 172) in 19595 ms on localhost (executor driver) (39/48)
19/03/29 14:18:57 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1409286144+33554432
19/03/29 14:19:13 INFO Executor: Finished task 42.0 in stage 16.0 (TID 176). 1402 bytes result sent to driver
19/03/29 14:19:13 INFO TaskSetManager: Starting task 43.0 in stage 16.0 (TID 177, localhost, executor driver, partition 43, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:19:13 INFO Executor: Running task 43.0 in stage 16.0 (TID 177)
19/03/29 14:19:13 INFO TaskSetManager: Finished task 42.0 in stage 16.0 (TID 176) in 16243 ms on localhost (executor driver) (40/48)
19/03/29 14:19:13 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1442840576+33554432
19/03/29 14:19:14 INFO Executor: Finished task 40.0 in stage 16.0 (TID 174). 1402 bytes result sent to driver
19/03/29 14:19:14 INFO TaskSetManager: Starting task 44.0 in stage 16.0 (TID 178, localhost, executor driver, partition 44, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:19:14 INFO TaskSetManager: Finished task 40.0 in stage 16.0 (TID 174) in 18050 ms on localhost (executor driver) (41/48)
19/03/29 14:19:14 INFO Executor: Running task 44.0 in stage 16.0 (TID 178)
19/03/29 14:19:14 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1476395008+33554432
19/03/29 14:19:16 INFO Executor: Finished task 39.0 in stage 16.0 (TID 173). 1402 bytes result sent to driver
19/03/29 14:19:16 INFO TaskSetManager: Starting task 45.0 in stage 16.0 (TID 179, localhost, executor driver, partition 45, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:19:16 INFO TaskSetManager: Finished task 39.0 in stage 16.0 (TID 173) in 20900 ms on localhost (executor driver) (42/48)
19/03/29 14:19:16 INFO Executor: Running task 45.0 in stage 16.0 (TID 179)
19/03/29 14:19:16 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1509949440+33554432
19/03/29 14:19:16 INFO Executor: Finished task 41.0 in stage 16.0 (TID 175). 1492 bytes result sent to driver
19/03/29 14:19:16 INFO TaskSetManager: Starting task 46.0 in stage 16.0 (TID 180, localhost, executor driver, partition 46, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:19:16 INFO Executor: Running task 46.0 in stage 16.0 (TID 180)
19/03/29 14:19:16 INFO TaskSetManager: Finished task 41.0 in stage 16.0 (TID 175) in 20190 ms on localhost (executor driver) (43/48)
19/03/29 14:19:16 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1543503872+33554432
19/03/29 14:19:27 INFO Executor: Finished task 43.0 in stage 16.0 (TID 177). 1402 bytes result sent to driver
19/03/29 14:19:27 INFO TaskSetManager: Starting task 47.0 in stage 16.0 (TID 181, localhost, executor driver, partition 47, PROCESS_LOCAL, 6070 bytes)
19/03/29 14:19:27 INFO Executor: Running task 47.0 in stage 16.0 (TID 181)
19/03/29 14:19:27 INFO TaskSetManager: Finished task 43.0 in stage 16.0 (TID 177) in 14534 ms on localhost (executor driver) (44/48)
19/03/29 14:19:27 INFO HadoopRDD: Input split: file:/C:/DataScience/Datasets/Crimes_-_2001_to_present.csv:1577058304+33608904
19/03/29 14:19:33 INFO Executor: Finished task 46.0 in stage 16.0 (TID 180). 1492 bytes result sent to driver
19/03/29 14:19:33 INFO TaskSetManager: Finished task 46.0 in stage 16.0 (TID 180) in 16510 ms on localhost (executor driver) (45/48)
19/03/29 14:19:38 INFO Executor: Finished task 44.0 in stage 16.0 (TID 178). 1492 bytes result sent to driver
19/03/29 14:19:38 INFO TaskSetManager: Finished task 44.0 in stage 16.0 (TID 178) in 24353 ms on localhost (executor driver) (46/48)
19/03/29 14:19:38 INFO Executor: Finished task 45.0 in stage 16.0 (TID 179). 1402 bytes result sent to driver
19/03/29 14:19:38 INFO TaskSetManager: Finished task 45.0 in stage 16.0 (TID 179) in 22447 ms on localhost (executor driver) (47/48)
19/03/29 14:19:43 INFO Executor: Finished task 47.0 in stage 16.0 (TID 181). 1492 bytes result sent to driver
19/03/29 14:19:43 INFO TaskSetManager: Finished task 47.0 in stage 16.0 (TID 181) in 15590 ms on localhost (executor driver) (48/48)
19/03/29 14:19:43 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/03/29 14:19:43 INFO DAGScheduler: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0) finished in 249.196 s
19/03/29 14:19:43 INFO DAGScheduler: Job 14 finished: csv at NativeMethodAccessorImpl.java:0, took 249.317363 s
19/03/29 14:19:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/03/29 14:19:44 INFO HiveMetaStore: 0: get_database: default
19/03/29 14:19:44 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 14:19:44 INFO HiveMetaStore: 0: get_database: default
19/03/29 14:19:44 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_database: default	
19/03/29 14:19:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/03/29 14:19:44 INFO audit: ugi=Gustavo	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/03/29 14:19:51 INFO SparkSqlParser: Parsing command: chicago_raw
19/03/29 14:19:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `chicago_raw`
19/03/29 14:19:51 INFO SparkSqlParser: Parsing command: `chicago_raw`
19/03/29 14:19:51 INFO FileSourceStrategy: Pruning directories with: 
19/03/29 14:19:52 INFO FileSourceStrategy: Post-Scan Filters: 
19/03/29 14:19:52 INFO FileSourceStrategy: Output Data Schema: struct<ID: int, Case Number: string, Date: string, Block: string, IUCR: string ... 20 more fields>
19/03/29 14:19:52 INFO FileSourceStrategy: Pushed Filters: 
19/03/29 14:19:52 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 282.7 KB, free 911.2 MB)
19/03/29 14:19:53 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.2 KB, free 911.2 MB)
19/03/29 14:19:53 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:50747 (size: 24.2 KB, free: 912.2 MB)
19/03/29 14:19:53 INFO SparkContext: Created broadcast 24 from sql at <unknown>:0
19/03/29 14:19:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
19/03/29 14:19:55 INFO SparkContext: Starting job: sql at <unknown>:0
19/03/29 14:19:55 INFO DAGScheduler: Registering RDD 68 (sql at <unknown>:0)
19/03/29 14:19:55 INFO DAGScheduler: Got job 15 (sql at <unknown>:0) with 1 output partitions
19/03/29 14:19:55 INFO DAGScheduler: Final stage: ResultStage 18 (sql at <unknown>:0)
19/03/29 14:19:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/03/29 14:19:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/03/29 14:19:55 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at sql at <unknown>:0), which has no missing parents
19/03/29 14:19:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 36.3 KB, free 911.1 MB)
19/03/29 14:19:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.1 KB, free 911.1 MB)
19/03/29 14:19:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:50747 (size: 15.1 KB, free: 912.2 MB)
19/03/29 14:19:55 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
19/03/29 14:19:55 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at sql at <unknown>:0)
19/03/29 14:19:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 13 tasks
19/03/29 14:19:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:19:55 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 183, localhost, executor driver, partition 1, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:19:55 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 184, localhost, executor driver, partition 2, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:19:55 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 185, localhost, executor driver, partition 3, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:19:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 182)
19/03/29 14:19:55 INFO Executor: Running task 1.0 in stage 17.0 (TID 183)
19/03/29 14:19:55 INFO Executor: Running task 2.0 in stage 17.0 (TID 184)
19/03/29 14:19:55 INFO Executor: Running task 3.0 in stage 17.0 (TID 185)
19/03/29 14:19:55 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 134217728-268435456, partition values: [empty row]
19/03/29 14:19:55 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 402653184-536870912, partition values: [empty row]
19/03/29 14:19:55 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 268435456-402653184, partition values: [empty row]
19/03/29 14:19:55 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 0-134217728, partition values: [empty row]
19/03/29 14:19:57 INFO ContextCleaner: Cleaned accumulator 4817
19/03/29 14:20:05 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:50747 in memory (size: 4.8 KB, free: 912.2 MB)
19/03/29 14:20:05 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.2 MB)
19/03/29 14:20:05 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:50747 in memory (size: 23.3 KB, free: 912.2 MB)
19/03/29 14:20:05 INFO BlockManager: Removing RDD 31
19/03/29 14:20:05 INFO ContextCleaner: Cleaned RDD 31
19/03/29 14:20:05 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:50747 in memory (size: 24.2 KB, free: 912.3 MB)
19/03/29 14:20:05 INFO ContextCleaner: Cleaned accumulator 2647
19/03/29 14:20:05 INFO ContextCleaner: Cleaned accumulator 2646
19/03/29 14:20:05 INFO ContextCleaner: Cleaned accumulator 2645
19/03/29 14:20:05 INFO ContextCleaner: Cleaned accumulator 2644
19/03/29 14:21:04 INFO MemoryStore: Block rdd_65_3 stored as values in memory (estimated size 64.0 MB, free 847.9 MB)
19/03/29 14:21:04 INFO BlockManagerInfo: Added rdd_65_3 in memory on 127.0.0.1:50747 (size: 64.0 MB, free: 848.2 MB)
19/03/29 14:21:05 INFO Executor: Finished task 3.0 in stage 17.0 (TID 185). 2980 bytes result sent to driver
19/03/29 14:21:05 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 186, localhost, executor driver, partition 4, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:21:05 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 185) in 70139 ms on localhost (executor driver) (1/13)
19/03/29 14:21:05 INFO Executor: Running task 4.0 in stage 17.0 (TID 186)
19/03/29 14:21:05 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 536870912-671088640, partition values: [empty row]
19/03/29 14:21:08 INFO MemoryStore: Block rdd_65_2 stored as values in memory (estimated size 65.1 MB, free 782.9 MB)
19/03/29 14:21:08 INFO BlockManagerInfo: Added rdd_65_2 in memory on 127.0.0.1:50747 (size: 65.1 MB, free: 783.2 MB)
19/03/29 14:21:09 INFO Executor: Finished task 2.0 in stage 17.0 (TID 184). 2893 bytes result sent to driver
19/03/29 14:21:09 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 187, localhost, executor driver, partition 5, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:21:09 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 184) in 73715 ms on localhost (executor driver) (2/13)
19/03/29 14:21:09 INFO Executor: Running task 5.0 in stage 17.0 (TID 187)
19/03/29 14:21:09 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 671088640-805306368, partition values: [empty row]
19/03/29 14:21:16 INFO MemoryStore: Block rdd_65_0 stored as values in memory (estimated size 65.3 MB, free 717.6 MB)
19/03/29 14:21:16 INFO BlockManagerInfo: Added rdd_65_0 in memory on 127.0.0.1:50747 (size: 65.3 MB, free: 717.9 MB)
19/03/29 14:21:17 INFO Executor: Finished task 0.0 in stage 17.0 (TID 182). 2893 bytes result sent to driver
19/03/29 14:21:17 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 188, localhost, executor driver, partition 6, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:21:17 INFO Executor: Running task 6.0 in stage 17.0 (TID 188)
19/03/29 14:21:17 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 182) in 81743 ms on localhost (executor driver) (3/13)
19/03/29 14:21:17 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 805306368-939524096, partition values: [empty row]
19/03/29 14:21:20 INFO MemoryStore: Block rdd_65_1 stored as values in memory (estimated size 65.2 MB, free 652.4 MB)
19/03/29 14:21:20 INFO BlockManagerInfo: Added rdd_65_1 in memory on 127.0.0.1:50747 (size: 65.2 MB, free: 652.8 MB)
19/03/29 14:21:21 INFO Executor: Finished task 1.0 in stage 17.0 (TID 183). 2893 bytes result sent to driver
19/03/29 14:21:21 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 189, localhost, executor driver, partition 7, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:21:21 INFO Executor: Running task 7.0 in stage 17.0 (TID 189)
19/03/29 14:21:21 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 939524096-1073741824, partition values: [empty row]
19/03/29 14:21:21 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 183) in 85710 ms on localhost (executor driver) (4/13)
19/03/29 14:22:03 INFO MemoryStore: Block rdd_65_6 stored as values in memory (estimated size 69.3 MB, free 583.1 MB)
19/03/29 14:22:03 INFO BlockManagerInfo: Added rdd_65_6 in memory on 127.0.0.1:50747 (size: 69.3 MB, free: 583.4 MB)
19/03/29 14:22:03 INFO Executor: Finished task 6.0 in stage 17.0 (TID 188). 2983 bytes result sent to driver
19/03/29 14:22:03 INFO TaskSetManager: Starting task 8.0 in stage 17.0 (TID 190, localhost, executor driver, partition 8, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:22:03 INFO Executor: Running task 8.0 in stage 17.0 (TID 190)
19/03/29 14:22:03 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 188) in 46465 ms on localhost (executor driver) (5/13)
19/03/29 14:22:03 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1073741824-1207959552, partition values: [empty row]
19/03/29 14:22:06 INFO MemoryStore: Block rdd_65_4 stored as values in memory (estimated size 68.8 MB, free 514.3 MB)
19/03/29 14:22:06 INFO BlockManagerInfo: Added rdd_65_4 in memory on 127.0.0.1:50747 (size: 68.8 MB, free: 514.6 MB)
19/03/29 14:22:06 INFO Executor: Finished task 4.0 in stage 17.0 (TID 186). 2893 bytes result sent to driver
19/03/29 14:22:06 INFO TaskSetManager: Starting task 9.0 in stage 17.0 (TID 191, localhost, executor driver, partition 9, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:22:06 INFO Executor: Running task 9.0 in stage 17.0 (TID 191)
19/03/29 14:22:06 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 186) in 61527 ms on localhost (executor driver) (6/13)
19/03/29 14:22:06 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1207959552-1342177280, partition values: [empty row]
19/03/29 14:22:11 INFO MemoryStore: Block rdd_65_5 stored as values in memory (estimated size 67.7 MB, free 446.6 MB)
19/03/29 14:22:11 INFO BlockManagerInfo: Added rdd_65_5 in memory on 127.0.0.1:50747 (size: 67.7 MB, free: 446.9 MB)
19/03/29 14:22:11 INFO Executor: Finished task 5.0 in stage 17.0 (TID 187). 2893 bytes result sent to driver
19/03/29 14:22:11 INFO TaskSetManager: Starting task 10.0 in stage 17.0 (TID 192, localhost, executor driver, partition 10, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:22:11 INFO Executor: Running task 10.0 in stage 17.0 (TID 192)
19/03/29 14:22:11 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 187) in 62919 ms on localhost (executor driver) (7/13)
19/03/29 14:22:11 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1342177280-1476395008, partition values: [empty row]
19/03/29 14:22:12 INFO MemoryStore: Block rdd_65_7 stored as values in memory (estimated size 66.7 MB, free 379.9 MB)
19/03/29 14:22:12 INFO BlockManagerInfo: Added rdd_65_7 in memory on 127.0.0.1:50747 (size: 66.7 MB, free: 380.2 MB)
19/03/29 14:22:13 INFO Executor: Finished task 7.0 in stage 17.0 (TID 189). 2893 bytes result sent to driver
19/03/29 14:22:13 INFO TaskSetManager: Starting task 11.0 in stage 17.0 (TID 193, localhost, executor driver, partition 11, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:22:13 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 189) in 52081 ms on localhost (executor driver) (8/13)
19/03/29 14:22:13 INFO Executor: Running task 11.0 in stage 17.0 (TID 193)
19/03/29 14:22:13 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1476395008-1610612736, partition values: [empty row]
19/03/29 14:23:04 INFO MemoryStore: Block rdd_65_10 stored as values in memory (estimated size 66.6 MB, free 313.3 MB)
19/03/29 14:23:04 INFO BlockManagerInfo: Added rdd_65_10 in memory on 127.0.0.1:50747 (size: 66.6 MB, free: 313.6 MB)
19/03/29 14:23:04 INFO Executor: Finished task 10.0 in stage 17.0 (TID 192). 2893 bytes result sent to driver
19/03/29 14:23:04 INFO TaskSetManager: Starting task 12.0 in stage 17.0 (TID 194, localhost, executor driver, partition 12, PROCESS_LOCAL, 6600 bytes)
19/03/29 14:23:04 INFO Executor: Running task 12.0 in stage 17.0 (TID 194)
19/03/29 14:23:04 INFO TaskSetManager: Finished task 10.0 in stage 17.0 (TID 192) in 52412 ms on localhost (executor driver) (9/13)
19/03/29 14:23:04 INFO FileScanRDD: Reading File path: file:///C:/DataScience/Datasets/Crimes_-_2001_to_present.csv, range: 1610612736-1610667208, partition values: [empty row]
19/03/29 14:23:04 INFO MemoryStore: Block rdd_65_12 stored as values in memory (estimated size 36.9 KB, free 313.3 MB)
19/03/29 14:23:04 INFO BlockManagerInfo: Added rdd_65_12 in memory on 127.0.0.1:50747 (size: 36.9 KB, free: 313.6 MB)
19/03/29 14:23:04 INFO Executor: Finished task 12.0 in stage 17.0 (TID 194). 2820 bytes result sent to driver
19/03/29 14:23:04 INFO TaskSetManager: Finished task 12.0 in stage 17.0 (TID 194) in 556 ms on localhost (executor driver) (10/13)
19/03/29 14:23:07 INFO MemoryStore: Block rdd_65_8 stored as values in memory (estimated size 64.2 MB, free 249.1 MB)
19/03/29 14:23:07 INFO BlockManagerInfo: Added rdd_65_8 in memory on 127.0.0.1:50747 (size: 64.2 MB, free: 249.4 MB)
19/03/29 14:23:07 INFO Executor: Finished task 8.0 in stage 17.0 (TID 190). 2893 bytes result sent to driver
19/03/29 14:23:07 INFO TaskSetManager: Finished task 8.0 in stage 17.0 (TID 190) in 64412 ms on localhost (executor driver) (11/13)
19/03/29 14:23:08 INFO MemoryStore: Block rdd_65_9 stored as values in memory (estimated size 65.3 MB, free 183.7 MB)
19/03/29 14:23:08 INFO BlockManagerInfo: Added rdd_65_9 in memory on 127.0.0.1:50747 (size: 65.3 MB, free: 184.0 MB)
19/03/29 14:23:08 INFO Executor: Finished task 9.0 in stage 17.0 (TID 191). 2893 bytes result sent to driver
19/03/29 14:23:08 INFO TaskSetManager: Finished task 9.0 in stage 17.0 (TID 191) in 61793 ms on localhost (executor driver) (12/13)
19/03/29 14:23:17 INFO MemoryStore: Block rdd_65_11 stored as values in memory (estimated size 65.7 MB, free 118.1 MB)
19/03/29 14:23:17 INFO BlockManagerInfo: Added rdd_65_11 in memory on 127.0.0.1:50747 (size: 65.7 MB, free: 118.4 MB)
19/03/29 14:23:17 INFO Executor: Finished task 11.0 in stage 17.0 (TID 193). 2893 bytes result sent to driver
19/03/29 14:23:17 INFO TaskSetManager: Finished task 11.0 in stage 17.0 (TID 193) in 64262 ms on localhost (executor driver) (13/13)
19/03/29 14:23:17 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/03/29 14:23:17 INFO DAGScheduler: ShuffleMapStage 17 (sql at <unknown>:0) finished in 202.025 s
19/03/29 14:23:17 INFO DAGScheduler: looking for newly runnable stages
19/03/29 14:23:17 INFO DAGScheduler: running: Set()
19/03/29 14:23:17 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/03/29 14:23:17 INFO DAGScheduler: failed: Set()
19/03/29 14:23:17 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[71] at sql at <unknown>:0), which has no missing parents
19/03/29 14:23:17 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 118.1 MB)
19/03/29 14:23:17 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 118.0 MB)
19/03/29 14:23:17 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:50747 (size: 3.7 KB, free: 118.4 MB)
19/03/29 14:23:17 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
19/03/29 14:23:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[71] at sql at <unknown>:0)
19/03/29 14:23:17 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/03/29 14:23:17 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 195, localhost, executor driver, partition 0, ANY, 5954 bytes)
19/03/29 14:23:17 INFO Executor: Running task 0.0 in stage 18.0 (TID 195)
19/03/29 14:23:17 INFO ShuffleBlockFetcherIterator: Getting 13 non-empty blocks out of 13 blocks
19/03/29 14:23:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/03/29 14:23:17 INFO Executor: Finished task 0.0 in stage 18.0 (TID 195). 1873 bytes result sent to driver
19/03/29 14:23:17 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 195) in 194 ms on localhost (executor driver) (1/1)
19/03/29 14:23:17 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/03/29 14:23:17 INFO DAGScheduler: ResultStage 18 (sql at <unknown>:0) finished in 0.194 s
19/03/29 14:23:17 INFO DAGScheduler: Job 15 finished: sql at <unknown>:0, took 202.241506 s
19/03/29 14:23:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `chicago_raw`
19/03/29 14:23:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/03/29 14:23:32 INFO DAGScheduler: Registering RDD 75 (collect at utils.scala:204)
19/03/29 14:23:32 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 1 output partitions
19/03/29 14:23:32 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:204)
19/03/29 14:23:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/03/29 14:23:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/03/29 14:23:32 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[75] at collect at utils.scala:204), which has no missing parents
19/03/29 14:23:32 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 36.3 KB, free 118.0 MB)
19/03/29 14:23:32 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 15.1 KB, free 118.0 MB)
19/03/29 14:23:32 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:50747 (size: 15.1 KB, free: 118.4 MB)
19/03/29 14:23:32 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
19/03/29 14:23:32 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[75] at collect at utils.scala:204)
19/03/29 14:23:32 INFO TaskSchedulerImpl: Adding task set 19.0 with 13 tasks
19/03/29 14:23:32 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:32 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 197, localhost, executor driver, partition 1, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:32 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 198, localhost, executor driver, partition 2, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:32 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 199, localhost, executor driver, partition 3, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:32 INFO Executor: Running task 1.0 in stage 19.0 (TID 197)
19/03/29 14:23:32 INFO Executor: Running task 0.0 in stage 19.0 (TID 196)
19/03/29 14:23:32 INFO Executor: Running task 3.0 in stage 19.0 (TID 199)
19/03/29 14:23:32 INFO Executor: Running task 2.0 in stage 19.0 (TID 198)
19/03/29 14:23:32 INFO BlockManager: Found block rdd_65_1 locally
19/03/29 14:23:32 INFO BlockManager: Found block rdd_65_2 locally
19/03/29 14:23:32 INFO BlockManager: Found block rdd_65_3 locally
19/03/29 14:23:32 INFO BlockManager: Found block rdd_65_0 locally
19/03/29 14:23:33 INFO Executor: Finished task 1.0 in stage 19.0 (TID 197). 2109 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Starting task 4.0 in stage 19.0 (TID 200, localhost, executor driver, partition 4, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO Executor: Running task 4.0 in stage 19.0 (TID 200)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 197) in 160 ms on localhost (executor driver) (1/13)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_4 locally
19/03/29 14:23:33 INFO Executor: Finished task 2.0 in stage 19.0 (TID 198). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO Executor: Finished task 3.0 in stage 19.0 (TID 199). 2019 bytes result sent to driver
19/03/29 14:23:33 INFO Executor: Finished task 0.0 in stage 19.0 (TID 196). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Starting task 5.0 in stage 19.0 (TID 201, localhost, executor driver, partition 5, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 198) in 186 ms on localhost (executor driver) (2/13)
19/03/29 14:23:33 INFO Executor: Running task 5.0 in stage 19.0 (TID 201)
19/03/29 14:23:33 INFO TaskSetManager: Starting task 6.0 in stage 19.0 (TID 202, localhost, executor driver, partition 6, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO Executor: Running task 6.0 in stage 19.0 (TID 202)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_5 locally
19/03/29 14:23:33 INFO TaskSetManager: Starting task 7.0 in stage 19.0 (TID 203, localhost, executor driver, partition 7, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 199) in 194 ms on localhost (executor driver) (3/13)
19/03/29 14:23:33 INFO Executor: Running task 7.0 in stage 19.0 (TID 203)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_6 locally
19/03/29 14:23:33 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 196) in 199 ms on localhost (executor driver) (4/13)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_7 locally
19/03/29 14:23:33 INFO Executor: Finished task 4.0 in stage 19.0 (TID 200). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Starting task 8.0 in stage 19.0 (TID 204, localhost, executor driver, partition 8, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO Executor: Running task 8.0 in stage 19.0 (TID 204)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 4.0 in stage 19.0 (TID 200) in 90 ms on localhost (executor driver) (5/13)
19/03/29 14:23:33 INFO Executor: Finished task 5.0 in stage 19.0 (TID 201). 2188 bytes result sent to driver
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_8 locally
19/03/29 14:23:33 INFO TaskSetManager: Starting task 9.0 in stage 19.0 (TID 205, localhost, executor driver, partition 9, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 5.0 in stage 19.0 (TID 201) in 68 ms on localhost (executor driver) (6/13)
19/03/29 14:23:33 INFO Executor: Running task 9.0 in stage 19.0 (TID 205)
19/03/29 14:23:33 INFO Executor: Finished task 7.0 in stage 19.0 (TID 203). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_9 locally
19/03/29 14:23:33 INFO TaskSetManager: Starting task 10.0 in stage 19.0 (TID 206, localhost, executor driver, partition 10, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO Executor: Running task 10.0 in stage 19.0 (TID 206)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 7.0 in stage 19.0 (TID 203) in 76 ms on localhost (executor driver) (7/13)
19/03/29 14:23:33 INFO Executor: Finished task 6.0 in stage 19.0 (TID 202). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_10 locally
19/03/29 14:23:33 INFO TaskSetManager: Starting task 11.0 in stage 19.0 (TID 207, localhost, executor driver, partition 11, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 6.0 in stage 19.0 (TID 202) in 82 ms on localhost (executor driver) (8/13)
19/03/29 14:23:33 INFO Executor: Running task 11.0 in stage 19.0 (TID 207)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_11 locally
19/03/29 14:23:33 INFO Executor: Finished task 8.0 in stage 19.0 (TID 204). 2275 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Starting task 12.0 in stage 19.0 (TID 208, localhost, executor driver, partition 12, PROCESS_LOCAL, 6592 bytes)
19/03/29 14:23:33 INFO Executor: Running task 12.0 in stage 19.0 (TID 208)
19/03/29 14:23:33 INFO TaskSetManager: Finished task 8.0 in stage 19.0 (TID 204) in 102 ms on localhost (executor driver) (9/13)
19/03/29 14:23:33 INFO Executor: Finished task 11.0 in stage 19.0 (TID 207). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Finished task 11.0 in stage 19.0 (TID 207) in 87 ms on localhost (executor driver) (10/13)
19/03/29 14:23:33 INFO BlockManager: Found block rdd_65_12 locally
19/03/29 14:23:33 INFO Executor: Finished task 10.0 in stage 19.0 (TID 206). 2109 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Finished task 10.0 in stage 19.0 (TID 206) in 98 ms on localhost (executor driver) (11/13)
19/03/29 14:23:33 INFO Executor: Finished task 9.0 in stage 19.0 (TID 205). 2098 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Finished task 9.0 in stage 19.0 (TID 205) in 122 ms on localhost (executor driver) (12/13)
19/03/29 14:23:33 INFO Executor: Finished task 12.0 in stage 19.0 (TID 208). 2019 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Finished task 12.0 in stage 19.0 (TID 208) in 38 ms on localhost (executor driver) (13/13)
19/03/29 14:23:33 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/03/29 14:23:33 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:204) finished in 0.389 s
19/03/29 14:23:33 INFO DAGScheduler: looking for newly runnable stages
19/03/29 14:23:33 INFO DAGScheduler: running: Set()
19/03/29 14:23:33 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/03/29 14:23:33 INFO DAGScheduler: failed: Set()
19/03/29 14:23:33 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/03/29 14:23:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 118.0 MB)
19/03/29 14:23:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 118.0 MB)
19/03/29 14:23:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:50747 (size: 3.7 KB, free: 118.3 MB)
19/03/29 14:23:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
19/03/29 14:23:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[78] at collect at utils.scala:204)
19/03/29 14:23:33 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/03/29 14:23:33 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 209, localhost, executor driver, partition 0, ANY, 5946 bytes)
19/03/29 14:23:33 INFO Executor: Running task 0.0 in stage 20.0 (TID 209)
19/03/29 14:23:33 INFO ShuffleBlockFetcherIterator: Getting 13 non-empty blocks out of 13 blocks
19/03/29 14:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/03/29 14:23:33 INFO Executor: Finished task 0.0 in stage 20.0 (TID 209). 1952 bytes result sent to driver
19/03/29 14:23:33 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 209) in 138 ms on localhost (executor driver) (1/1)
19/03/29 14:23:33 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/03/29 14:23:33 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:204) finished in 0.139 s
19/03/29 14:23:33 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.586957 s
19/03/29 14:23:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw` AS `zzz2`
WHERE (0 = 1)
19/03/29 14:26:18 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `mejtimnbdf`) `llnhukgdyo`
19/03/29 14:26:32 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `sszpakjzvi`) `ovrzwbuuxo`
19/03/29 14:26:47 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `ocrikxlkfg`) `qsyfgyvisb`
19/03/29 14:27:46 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `dhovepdroo`) `oapxfafhnn`
19/03/29 14:27:50 INFO SparkSqlParser: Parsing command: SELECT `ID`, `Case_Number`, YMD(CAST(`DateTime` AS DATE)) AS `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, `DateTime`, MONTH(`DateTime`) AS `Month`, HOUR(`DateTime`) AS `Hour`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`, MDY_HMS(`Date`, "America/Chicago" AS "tz") AS `DateTime`
FROM (SELECT `ID`, `Case_Number`, `Date`, `Primary_Type`, `Description`, `Location_Description`, `Arrest`, `X_Coordinate`, `Y_Coordinate`, `Year`, `Latitude`, `Longitude`, `Location`
FROM `chicago_raw`) `wohwovqxsz`) `koiwjltobb`
19/03/29 14:28:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
19/03/29 14:28:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
19/03/29 14:28:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 11
19/03/29 14:28:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
LIMIT 11
19/03/29 14:28:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/03/29 14:28:01 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/03/29 14:28:01 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/03/29 14:28:01 INFO DAGScheduler: Parents of final stage: List()
19/03/29 14:28:01 INFO DAGScheduler: Missing parents: List()
19/03/29 14:28:01 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:204), which has no missing parents
19/03/29 14:28:01 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 32.3 KB, free 118.0 MB)
19/03/29 14:28:01 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.1 KB, free 117.9 MB)
19/03/29 14:28:01 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:50747 (size: 13.1 KB, free: 118.3 MB)
19/03/29 14:28:01 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
19/03/29 14:28:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[80] at collect at utils.scala:204)
19/03/29 14:28:01 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/03/29 14:28:01 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 6517 bytes)
19/03/29 14:28:01 INFO Executor: Running task 0.0 in stage 21.0 (TID 210)
19/03/29 14:28:01 INFO BlockManager: Found block rdd_65_0 locally
19/03/29 14:28:01 WARN Executor: 1 block locks were not released by TID = 210:
[rdd_65_0]
19/03/29 14:28:01 INFO Executor: Finished task 0.0 in stage 21.0 (TID 210). 3620 bytes result sent to driver
19/03/29 14:28:01 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 210) in 20 ms on localhost (executor driver) (1/1)
19/03/29 14:28:01 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/03/29 14:28:01 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.020 s
19/03/29 14:28:01 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.030164 s
19/03/29 14:28:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `chicago_raw`
19/03/29 14:32:59 INFO SparkContext: Invoking stop() from shutdown hook
19/03/29 14:32:59 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/03/29 14:32:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/03/29 14:33:00 INFO MemoryStore: MemoryStore cleared
19/03/29 14:33:00 INFO BlockManager: BlockManager stopped
19/03/29 14:33:00 INFO BlockManagerMaster: BlockManagerMaster stopped
19/03/29 14:33:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/03/29 14:33:00 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058
java.io.IOException: Failed to delete: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/03/29 14:33:00 INFO SparkContext: Successfully stopped SparkContext
19/03/29 14:33:00 INFO ShutdownHookManager: Shutdown hook called
19/03/29 14:33:00 INFO ShutdownHookManager: Deleting directory C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058
19/03/29 14:33:00 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058
java.io.IOException: Failed to delete: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac\userFiles-cb2aca32-fe3a-4b16-b26b-4c1e59d71058
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/03/29 14:33:00 INFO ShutdownHookManager: Deleting directory C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac
19/03/29 14:33:00 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac
java.io.IOException: Failed to delete: C:\Users\Gustavo\AppData\Local\Temp\spark-25ccc23e-0924-43d6-96b3-c7034bef0eac
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
